{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep Convolutional GANs\n",
    "\n",
    "# Importing the libraries\n",
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Setting some hyperparameters\n",
    "batchSize = 64 # We set the size of the batch.\n",
    "imageSize = 64 # We set the size of the generated images (64x64)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/torchvision/transforms/transforms.py:210: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
      "  warnings.warn(\"The use of the transforms.Scale transform is deprecated, \" +\n",
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 170254336/170498071 [02:05<00:00, 1223235.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "170500096it [02:20, 1223235.11it/s]                               "
     ]
    }
   ],
   "source": [
    "# Creating the transformations\n",
    "transform = transforms.Compose([transforms.Scale(imageSize), transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),]) # We create a list of transformations (scaling, tensor conversion, normalization) to apply to the input images.\n",
    "\n",
    "# Loading the dataset\n",
    "dataset = dset.CIFAR10(root = './data', download = True, transform = transform) # We download the training set in the ./data folder and we apply the previous transformations on each image.\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size = batchSize, shuffle = True, num_workers = 2) # We use dataLoader to get the images of the training set batch by batch.\n",
    "\n",
    "# Defining the weights_init function that takes as input a neural network m and that will initialize all its weights.\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class G(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(G,self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "        nn.ConvTranspose2d(100,512,4,1,0,bias = False),\n",
    "        nn.BatchNorm2d(512),\n",
    "        nn.ReLU(True),\n",
    "        nn.ConvTranspose2d(512,256,4,2,1,bias=False),\n",
    "        nn.BatchNorm2d(256),\n",
    "        nn.ReLU(True),\n",
    "        nn.ConvTranspose2d(256,128,4,2,1,bias=False),   \n",
    "        nn.BatchNorm2d(128),\n",
    "        nn.ReLU(True),\n",
    "        nn.ConvTranspose2d(128,64,4,2,1,bias=False),   \n",
    "        nn.BatchNorm2d(64),\n",
    "        nn.ReLU(True),\n",
    "        nn.ConvTranspose2d(64,3,4,2,1,bias=False),   \n",
    "        nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self,input):\n",
    "        output = self.main(input)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "G(\n",
       "  (main): Sequential(\n",
       "    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (13): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netG = G()\n",
    "netG.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class D(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(D,self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 4, 2, 1, bias = False),\n",
    "            nn.LeakyReLU(0.2,inplace=True),\n",
    "            nn.Conv2d(64, 128, 4, 2, 1, bias = False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2,inplace=True),\n",
    "            nn.Conv2d(128, 256, 4, 2, 1, bias = False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2,inplace=True),\n",
    "            nn.Conv2d(256, 512, 4, 2, 1, bias = False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2,inplace=True),\n",
    "            nn.Conv2d(512, 1, 4, 1, 0, bias = False),\n",
    "            nn.Sigmoid()\n",
    "            )\n",
    "        \n",
    "    def forward(self,input):\n",
    "        output = self.main(input)\n",
    "        return output.view(-1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "D(\n",
       "  (main): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
       "    (12): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netD = D()\n",
    "netD.apply(weights_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizerD = optim.Adam(netD.parameters(),lr=0.0002,betas=(0.5,0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(),lr=0.0002,betas=(0.5,0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/25][0/782] Loss_D: 1.3440 Loss_G: 7.4288\n",
      "[0/25][1/782] Loss_D: 0.7411 Loss_G: 7.8295\n",
      "[0/25][2/782] Loss_D: 0.9017 Loss_G: 8.5447\n",
      "[0/25][3/782] Loss_D: 0.9890 Loss_G: 8.2272\n",
      "[0/25][4/782] Loss_D: 1.0104 Loss_G: 10.0585\n",
      "[0/25][5/782] Loss_D: 0.3367 Loss_G: 8.5207\n",
      "[0/25][6/782] Loss_D: 0.8483 Loss_G: 11.4859\n",
      "[0/25][7/782] Loss_D: 0.4232 Loss_G: 8.4744\n",
      "[0/25][8/782] Loss_D: 1.3623 Loss_G: 13.5716\n",
      "[0/25][9/782] Loss_D: 0.5810 Loss_G: 9.9661\n",
      "[0/25][10/782] Loss_D: 0.8197 Loss_G: 12.0120\n",
      "[0/25][11/782] Loss_D: 0.5015 Loss_G: 9.0681\n",
      "[0/25][12/782] Loss_D: 1.1789 Loss_G: 15.7198\n",
      "[0/25][13/782] Loss_D: 0.6098 Loss_G: 12.3165\n",
      "[0/25][14/782] Loss_D: 0.5917 Loss_G: 11.1134\n",
      "[0/25][15/782] Loss_D: 0.7160 Loss_G: 15.2336\n",
      "[0/25][16/782] Loss_D: 0.3985 Loss_G: 11.7431\n",
      "[0/25][17/782] Loss_D: 0.3899 Loss_G: 10.1914\n",
      "[0/25][18/782] Loss_D: 0.7470 Loss_G: 16.0262\n",
      "[0/25][19/782] Loss_D: 0.4703 Loss_G: 12.9619\n",
      "[0/25][20/782] Loss_D: 0.1826 Loss_G: 7.5673\n",
      "[0/25][21/782] Loss_D: 2.8654 Loss_G: 20.9725\n",
      "[0/25][22/782] Loss_D: 0.4972 Loss_G: 22.3437\n",
      "[0/25][23/782] Loss_D: 0.1763 Loss_G: 17.5487\n",
      "[0/25][24/782] Loss_D: 0.1847 Loss_G: 8.3747\n",
      "[0/25][25/782] Loss_D: 2.2431 Loss_G: 19.4093\n",
      "[0/25][26/782] Loss_D: 0.2011 Loss_G: 21.2085\n",
      "[0/25][27/782] Loss_D: 0.3252 Loss_G: 16.8762\n",
      "[0/25][28/782] Loss_D: 0.0989 Loss_G: 8.1648\n",
      "[0/25][29/782] Loss_D: 2.4137 Loss_G: 19.9128\n",
      "[0/25][30/782] Loss_D: 0.6735 Loss_G: 20.8052\n",
      "[0/25][31/782] Loss_D: 0.3203 Loss_G: 15.7648\n",
      "[0/25][32/782] Loss_D: 0.1251 Loss_G: 6.4047\n",
      "[0/25][33/782] Loss_D: 2.7615 Loss_G: 21.6535\n",
      "[0/25][34/782] Loss_D: 0.2001 Loss_G: 24.9557\n",
      "[0/25][35/782] Loss_D: 0.3714 Loss_G: 22.3560\n",
      "[0/25][36/782] Loss_D: 0.2849 Loss_G: 15.7537\n",
      "[0/25][37/782] Loss_D: 0.0259 Loss_G: 6.4816\n",
      "[0/25][38/782] Loss_D: 2.3631 Loss_G: 21.0132\n",
      "[0/25][39/782] Loss_D: 0.1206 Loss_G: 24.3722\n",
      "[0/25][40/782] Loss_D: 0.4397 Loss_G: 22.0534\n",
      "[0/25][41/782] Loss_D: 0.0654 Loss_G: 16.0477\n",
      "[0/25][42/782] Loss_D: 0.0838 Loss_G: 8.0261\n",
      "[0/25][43/782] Loss_D: 1.1856 Loss_G: 19.6343\n",
      "[0/25][44/782] Loss_D: 0.2269 Loss_G: 21.7915\n",
      "[0/25][45/782] Loss_D: 0.3725 Loss_G: 18.2662\n",
      "[0/25][46/782] Loss_D: 0.0874 Loss_G: 12.7530\n",
      "[0/25][47/782] Loss_D: 0.0688 Loss_G: 5.6153\n",
      "[0/25][48/782] Loss_D: 2.2313 Loss_G: 23.1863\n",
      "[0/25][49/782] Loss_D: 0.3240 Loss_G: 27.2474\n",
      "[0/25][50/782] Loss_D: 0.3225 Loss_G: 26.9409\n",
      "[0/25][51/782] Loss_D: 0.1100 Loss_G: 24.6962\n",
      "[0/25][52/782] Loss_D: 0.2792 Loss_G: 19.8557\n",
      "[0/25][53/782] Loss_D: 0.0440 Loss_G: 13.2105\n",
      "[0/25][54/782] Loss_D: 0.0125 Loss_G: 6.1857\n",
      "[0/25][55/782] Loss_D: 1.0907 Loss_G: 19.7930\n",
      "[0/25][56/782] Loss_D: 0.1817 Loss_G: 22.7806\n",
      "[0/25][57/782] Loss_D: 0.1608 Loss_G: 20.9720\n",
      "[0/25][58/782] Loss_D: 0.3182 Loss_G: 15.2237\n",
      "[0/25][59/782] Loss_D: 0.1162 Loss_G: 7.6991\n",
      "[0/25][60/782] Loss_D: 0.5934 Loss_G: 15.6515\n",
      "[0/25][61/782] Loss_D: 0.0684 Loss_G: 16.5666\n",
      "[0/25][62/782] Loss_D: 0.1488 Loss_G: 13.6693\n",
      "[0/25][63/782] Loss_D: 0.0543 Loss_G: 8.4835\n",
      "[0/25][64/782] Loss_D: 0.2851 Loss_G: 9.6744\n",
      "[0/25][65/782] Loss_D: 0.1868 Loss_G: 8.6927\n",
      "[0/25][66/782] Loss_D: 0.3469 Loss_G: 11.9339\n",
      "[0/25][67/782] Loss_D: 0.1185 Loss_G: 10.0067\n",
      "[0/25][68/782] Loss_D: 0.1959 Loss_G: 8.4808\n",
      "[0/25][69/782] Loss_D: 0.2960 Loss_G: 12.3244\n",
      "[0/25][70/782] Loss_D: 0.1193 Loss_G: 10.6935\n",
      "[0/25][71/782] Loss_D: 0.0368 Loss_G: 7.1675\n",
      "[0/25][72/782] Loss_D: 0.2988 Loss_G: 12.5548\n",
      "[0/25][73/782] Loss_D: 0.0527 Loss_G: 12.6051\n",
      "[0/25][74/782] Loss_D: 0.0756 Loss_G: 9.5371\n",
      "[0/25][75/782] Loss_D: 0.0807 Loss_G: 5.6449\n",
      "[0/25][76/782] Loss_D: 0.4638 Loss_G: 17.1510\n",
      "[0/25][77/782] Loss_D: 0.1474 Loss_G: 19.1998\n",
      "[0/25][78/782] Loss_D: 0.1202 Loss_G: 17.1729\n",
      "[0/25][79/782] Loss_D: 0.0516 Loss_G: 12.7906\n",
      "[0/25][80/782] Loss_D: 0.0323 Loss_G: 8.3201\n",
      "[0/25][81/782] Loss_D: 0.1037 Loss_G: 5.3040\n",
      "[0/25][82/782] Loss_D: 0.4558 Loss_G: 17.2469\n",
      "[0/25][83/782] Loss_D: 0.1518 Loss_G: 20.0157\n",
      "[0/25][84/782] Loss_D: 0.1743 Loss_G: 18.1484\n",
      "[0/25][85/782] Loss_D: 0.0598 Loss_G: 14.0010\n",
      "[0/25][86/782] Loss_D: 0.0804 Loss_G: 8.8796\n",
      "[0/25][87/782] Loss_D: 0.1394 Loss_G: 7.6993\n",
      "[0/25][88/782] Loss_D: 0.2406 Loss_G: 14.4098\n",
      "[0/25][89/782] Loss_D: 0.0688 Loss_G: 13.7409\n",
      "[0/25][90/782] Loss_D: 0.2823 Loss_G: 8.4441\n",
      "[0/25][91/782] Loss_D: 0.1800 Loss_G: 9.6606\n",
      "[0/25][92/782] Loss_D: 0.0602 Loss_G: 8.4243\n",
      "[0/25][93/782] Loss_D: 0.1083 Loss_G: 7.4578\n",
      "[0/25][94/782] Loss_D: 0.1803 Loss_G: 9.1803\n",
      "[0/25][95/782] Loss_D: 0.1693 Loss_G: 6.4214\n",
      "[0/25][96/782] Loss_D: 0.2665 Loss_G: 13.5805\n",
      "[0/25][97/782] Loss_D: 0.2294 Loss_G: 12.2391\n",
      "[0/25][98/782] Loss_D: 0.1183 Loss_G: 7.5593\n",
      "[0/25][99/782] Loss_D: 0.1782 Loss_G: 9.0381\n",
      "[0/25][100/782] Loss_D: 0.1097 Loss_G: 7.4830\n",
      "[0/25][101/782] Loss_D: 0.1204 Loss_G: 8.2910\n",
      "[0/25][102/782] Loss_D: 0.1561 Loss_G: 6.9230\n",
      "[0/25][103/782] Loss_D: 0.1364 Loss_G: 11.1391\n",
      "[0/25][104/782] Loss_D: 0.1533 Loss_G: 8.4891\n",
      "[0/25][105/782] Loss_D: 0.1376 Loss_G: 4.9662\n",
      "[0/25][106/782] Loss_D: 0.6245 Loss_G: 24.3789\n",
      "[0/25][107/782] Loss_D: 1.6687 Loss_G: 22.7108\n",
      "[0/25][108/782] Loss_D: 0.1335 Loss_G: 19.5163\n",
      "[0/25][109/782] Loss_D: 0.1018 Loss_G: 14.7461\n",
      "[0/25][110/782] Loss_D: 0.0463 Loss_G: 8.9713\n",
      "[0/25][111/782] Loss_D: 0.1410 Loss_G: 6.3481\n",
      "[0/25][112/782] Loss_D: 0.2610 Loss_G: 13.4345\n",
      "[0/25][113/782] Loss_D: 0.3508 Loss_G: 10.6253\n",
      "[0/25][114/782] Loss_D: 0.2506 Loss_G: 4.3008\n",
      "[0/25][115/782] Loss_D: 0.6584 Loss_G: 17.3357\n",
      "[0/25][116/782] Loss_D: 0.8597 Loss_G: 15.8806\n",
      "[0/25][117/782] Loss_D: 0.2672 Loss_G: 11.3346\n",
      "[0/25][118/782] Loss_D: 0.0442 Loss_G: 6.0310\n",
      "[0/25][119/782] Loss_D: 0.4291 Loss_G: 8.8788\n",
      "[0/25][120/782] Loss_D: 0.1849 Loss_G: 8.0781\n",
      "[0/25][121/782] Loss_D: 0.2377 Loss_G: 5.5913\n",
      "[0/25][122/782] Loss_D: 0.5240 Loss_G: 10.6267\n",
      "[0/25][123/782] Loss_D: 0.9658 Loss_G: 6.2685\n",
      "[0/25][124/782] Loss_D: 0.3951 Loss_G: 5.7213\n",
      "[0/25][125/782] Loss_D: 0.2638 Loss_G: 6.5865\n",
      "[0/25][126/782] Loss_D: 0.3011 Loss_G: 4.7789\n",
      "[0/25][127/782] Loss_D: 0.4321 Loss_G: 8.1853\n",
      "[0/25][128/782] Loss_D: 0.4869 Loss_G: 5.3265\n",
      "[0/25][129/782] Loss_D: 0.3936 Loss_G: 8.1329\n",
      "[0/25][130/782] Loss_D: 0.5827 Loss_G: 4.8022\n",
      "[0/25][131/782] Loss_D: 0.5567 Loss_G: 8.3292\n",
      "[0/25][132/782] Loss_D: 0.8253 Loss_G: 4.5102\n",
      "[0/25][133/782] Loss_D: 0.3112 Loss_G: 5.6865\n",
      "[0/25][134/782] Loss_D: 0.2590 Loss_G: 6.5546\n",
      "[0/25][135/782] Loss_D: 0.2892 Loss_G: 4.3151\n",
      "[0/25][136/782] Loss_D: 0.3512 Loss_G: 6.3826\n",
      "[0/25][137/782] Loss_D: 0.2482 Loss_G: 4.9039\n",
      "[0/25][138/782] Loss_D: 0.3150 Loss_G: 3.5332\n",
      "[0/25][139/782] Loss_D: 0.5844 Loss_G: 7.8336\n",
      "[0/25][140/782] Loss_D: 0.7161 Loss_G: 3.2288\n",
      "[0/25][141/782] Loss_D: 0.7025 Loss_G: 8.7188\n",
      "[0/25][142/782] Loss_D: 0.6155 Loss_G: 6.2671\n",
      "[0/25][143/782] Loss_D: 0.2042 Loss_G: 4.5529\n",
      "[0/25][144/782] Loss_D: 0.3196 Loss_G: 5.4337\n",
      "[0/25][145/782] Loss_D: 0.2264 Loss_G: 5.3350\n",
      "[0/25][146/782] Loss_D: 0.2576 Loss_G: 3.7972\n",
      "[0/25][147/782] Loss_D: 0.3741 Loss_G: 6.2229\n",
      "[0/25][148/782] Loss_D: 0.4738 Loss_G: 2.9765\n",
      "[0/25][149/782] Loss_D: 0.8755 Loss_G: 11.1100\n",
      "[0/25][150/782] Loss_D: 2.5913 Loss_G: 4.6005\n",
      "[0/25][151/782] Loss_D: 0.1966 Loss_G: 2.9430\n",
      "[0/25][152/782] Loss_D: 0.7379 Loss_G: 8.0728\n",
      "[0/25][153/782] Loss_D: 0.9873 Loss_G: 3.9386\n",
      "[0/25][154/782] Loss_D: 0.4114 Loss_G: 3.6685\n",
      "[0/25][155/782] Loss_D: 0.4831 Loss_G: 4.8927\n",
      "[0/25][156/782] Loss_D: 0.2373 Loss_G: 4.6453\n",
      "[0/25][157/782] Loss_D: 0.2242 Loss_G: 4.0726\n",
      "[0/25][158/782] Loss_D: 0.3781 Loss_G: 2.9997\n",
      "[0/25][159/782] Loss_D: 0.5684 Loss_G: 7.0767\n",
      "[0/25][160/782] Loss_D: 0.6560 Loss_G: 4.2213\n",
      "[0/25][161/782] Loss_D: 0.4569 Loss_G: 5.6184\n",
      "[0/25][162/782] Loss_D: 0.3773 Loss_G: 3.4724\n",
      "[0/25][163/782] Loss_D: 0.9525 Loss_G: 9.0969\n",
      "[0/25][164/782] Loss_D: 0.8429 Loss_G: 6.8180\n",
      "[0/25][165/782] Loss_D: 0.1613 Loss_G: 3.9705\n",
      "[0/25][166/782] Loss_D: 0.5777 Loss_G: 7.6837\n",
      "[0/25][167/782] Loss_D: 0.4046 Loss_G: 5.9815\n",
      "[0/25][168/782] Loss_D: 0.3507 Loss_G: 4.3503\n",
      "[0/25][169/782] Loss_D: 0.3442 Loss_G: 6.2143\n",
      "[0/25][170/782] Loss_D: 0.2394 Loss_G: 5.1171\n",
      "[0/25][171/782] Loss_D: 0.3376 Loss_G: 4.9194\n",
      "[0/25][172/782] Loss_D: 0.3499 Loss_G: 4.7588\n",
      "[0/25][173/782] Loss_D: 0.2881 Loss_G: 5.1017\n",
      "[0/25][174/782] Loss_D: 0.1894 Loss_G: 5.1864\n",
      "[0/25][175/782] Loss_D: 0.3744 Loss_G: 4.6548\n",
      "[0/25][176/782] Loss_D: 0.2754 Loss_G: 6.1533\n",
      "[0/25][177/782] Loss_D: 0.2176 Loss_G: 4.4712\n",
      "[0/25][178/782] Loss_D: 0.4502 Loss_G: 6.5474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/25][179/782] Loss_D: 0.4253 Loss_G: 3.4374\n",
      "[0/25][180/782] Loss_D: 0.9845 Loss_G: 12.4519\n",
      "[0/25][181/782] Loss_D: 2.3035 Loss_G: 6.4247\n",
      "[0/25][182/782] Loss_D: 0.1461 Loss_G: 3.6550\n",
      "[0/25][183/782] Loss_D: 1.3695 Loss_G: 11.4226\n",
      "[0/25][184/782] Loss_D: 1.8508 Loss_G: 7.2578\n",
      "[0/25][185/782] Loss_D: 0.1179 Loss_G: 4.3682\n",
      "[0/25][186/782] Loss_D: 0.7443 Loss_G: 9.3583\n",
      "[0/25][187/782] Loss_D: 0.4757 Loss_G: 7.0337\n",
      "[0/25][188/782] Loss_D: 0.2185 Loss_G: 4.8008\n",
      "[0/25][189/782] Loss_D: 0.4457 Loss_G: 6.8602\n",
      "[0/25][190/782] Loss_D: 0.4282 Loss_G: 4.8986\n",
      "[0/25][191/782] Loss_D: 0.2725 Loss_G: 5.8286\n",
      "[0/25][192/782] Loss_D: 0.3205 Loss_G: 6.1888\n",
      "[0/25][193/782] Loss_D: 0.1434 Loss_G: 6.4549\n",
      "[0/25][194/782] Loss_D: 0.5850 Loss_G: 5.0285\n",
      "[0/25][195/782] Loss_D: 0.4526 Loss_G: 11.2013\n",
      "[0/25][196/782] Loss_D: 0.3995 Loss_G: 7.9488\n",
      "[0/25][197/782] Loss_D: 0.1390 Loss_G: 4.4186\n",
      "[0/25][198/782] Loss_D: 0.7813 Loss_G: 11.6971\n",
      "[0/25][199/782] Loss_D: 0.9613 Loss_G: 7.8002\n",
      "[0/25][200/782] Loss_D: 0.2770 Loss_G: 4.9865\n",
      "[0/25][201/782] Loss_D: 0.4959 Loss_G: 8.3833\n",
      "[0/25][202/782] Loss_D: 0.2156 Loss_G: 7.7742\n",
      "[0/25][203/782] Loss_D: 0.1129 Loss_G: 7.0821\n",
      "[0/25][204/782] Loss_D: 0.1861 Loss_G: 5.4124\n",
      "[0/25][205/782] Loss_D: 0.3626 Loss_G: 9.1294\n",
      "[0/25][206/782] Loss_D: 0.1445 Loss_G: 8.4285\n",
      "[0/25][207/782] Loss_D: 0.2164 Loss_G: 4.9418\n",
      "[0/25][208/782] Loss_D: 0.6245 Loss_G: 12.8292\n",
      "[0/25][209/782] Loss_D: 0.2379 Loss_G: 12.7419\n",
      "[0/25][210/782] Loss_D: 0.3772 Loss_G: 6.8485\n",
      "[0/25][211/782] Loss_D: 0.4709 Loss_G: 11.4180\n",
      "[0/25][212/782] Loss_D: 0.2431 Loss_G: 8.8901\n",
      "[0/25][213/782] Loss_D: 0.2205 Loss_G: 4.8605\n",
      "[0/25][214/782] Loss_D: 0.8052 Loss_G: 10.3894\n",
      "[0/25][215/782] Loss_D: 0.3227 Loss_G: 8.9527\n",
      "[0/25][216/782] Loss_D: 0.5975 Loss_G: 4.0069\n",
      "[0/25][217/782] Loss_D: 0.4262 Loss_G: 6.9305\n",
      "[0/25][218/782] Loss_D: 0.0944 Loss_G: 7.1984\n",
      "[0/25][219/782] Loss_D: 0.1314 Loss_G: 5.9787\n",
      "[0/25][220/782] Loss_D: 0.1339 Loss_G: 5.3092\n",
      "[0/25][221/782] Loss_D: 0.2982 Loss_G: 6.1916\n",
      "[0/25][222/782] Loss_D: 0.2326 Loss_G: 5.4515\n",
      "[0/25][223/782] Loss_D: 0.2444 Loss_G: 4.3197\n",
      "[0/25][224/782] Loss_D: 0.3389 Loss_G: 7.9309\n",
      "[0/25][225/782] Loss_D: 0.1485 Loss_G: 7.4774\n",
      "[0/25][226/782] Loss_D: 0.1446 Loss_G: 5.3389\n",
      "[0/25][227/782] Loss_D: 0.1399 Loss_G: 5.2390\n",
      "[0/25][228/782] Loss_D: 0.2270 Loss_G: 6.9003\n",
      "[0/25][229/782] Loss_D: 0.0925 Loss_G: 6.3366\n",
      "[0/25][230/782] Loss_D: 0.1295 Loss_G: 5.3032\n",
      "[0/25][231/782] Loss_D: 0.2042 Loss_G: 6.6093\n",
      "[0/25][232/782] Loss_D: 0.1386 Loss_G: 6.0015\n",
      "[0/25][233/782] Loss_D: 0.2505 Loss_G: 7.1828\n",
      "[0/25][234/782] Loss_D: 0.2414 Loss_G: 6.0035\n",
      "[0/25][235/782] Loss_D: 0.3028 Loss_G: 10.0113\n",
      "[0/25][236/782] Loss_D: 0.3335 Loss_G: 7.0355\n",
      "[0/25][237/782] Loss_D: 0.2227 Loss_G: 6.0676\n",
      "[0/25][238/782] Loss_D: 0.2524 Loss_G: 9.9025\n",
      "[0/25][239/782] Loss_D: 0.1226 Loss_G: 8.2361\n",
      "[0/25][240/782] Loss_D: 0.1493 Loss_G: 4.9323\n",
      "[0/25][241/782] Loss_D: 0.5042 Loss_G: 10.7514\n",
      "[0/25][242/782] Loss_D: 0.4122 Loss_G: 8.0963\n",
      "[0/25][243/782] Loss_D: 0.0697 Loss_G: 4.9421\n",
      "[0/25][244/782] Loss_D: 0.2478 Loss_G: 7.1561\n",
      "[0/25][245/782] Loss_D: 0.0719 Loss_G: 6.8675\n",
      "[0/25][246/782] Loss_D: 0.1092 Loss_G: 5.0829\n",
      "[0/25][247/782] Loss_D: 0.1583 Loss_G: 5.8824\n",
      "[0/25][248/782] Loss_D: 0.1110 Loss_G: 5.7940\n",
      "[0/25][249/782] Loss_D: 0.1234 Loss_G: 5.4038\n",
      "[0/25][250/782] Loss_D: 0.1026 Loss_G: 6.1079\n",
      "[0/25][251/782] Loss_D: 0.1092 Loss_G: 5.6331\n",
      "[0/25][252/782] Loss_D: 0.1370 Loss_G: 5.2451\n",
      "[0/25][253/782] Loss_D: 0.1230 Loss_G: 6.6406\n",
      "[0/25][254/782] Loss_D: 0.2068 Loss_G: 4.9768\n",
      "[0/25][255/782] Loss_D: 0.1288 Loss_G: 6.1667\n",
      "[0/25][256/782] Loss_D: 0.0695 Loss_G: 6.0220\n",
      "[0/25][257/782] Loss_D: 0.1877 Loss_G: 5.1376\n",
      "[0/25][258/782] Loss_D: 0.1859 Loss_G: 7.2890\n",
      "[0/25][259/782] Loss_D: 0.0918 Loss_G: 6.8213\n",
      "[0/25][260/782] Loss_D: 0.1190 Loss_G: 5.1325\n",
      "[0/25][261/782] Loss_D: 0.1968 Loss_G: 7.9768\n",
      "[0/25][262/782] Loss_D: 0.0919 Loss_G: 7.3241\n",
      "[0/25][263/782] Loss_D: 0.0743 Loss_G: 5.8090\n",
      "[0/25][264/782] Loss_D: 0.1625 Loss_G: 8.1975\n",
      "[0/25][265/782] Loss_D: 0.0979 Loss_G: 7.2229\n",
      "[0/25][266/782] Loss_D: 0.0533 Loss_G: 5.8364\n",
      "[0/25][267/782] Loss_D: 0.0948 Loss_G: 7.1808\n",
      "[0/25][268/782] Loss_D: 0.0686 Loss_G: 7.2660\n",
      "[0/25][269/782] Loss_D: 0.0723 Loss_G: 6.3770\n",
      "[0/25][270/782] Loss_D: 0.1159 Loss_G: 6.1670\n",
      "[0/25][271/782] Loss_D: 0.0971 Loss_G: 7.5630\n",
      "[0/25][272/782] Loss_D: 0.2601 Loss_G: 5.3676\n",
      "[0/25][273/782] Loss_D: 0.1269 Loss_G: 8.6737\n",
      "[0/25][274/782] Loss_D: 0.0197 Loss_G: 8.6417\n",
      "[0/25][275/782] Loss_D: 0.0329 Loss_G: 7.1178\n",
      "[0/25][276/782] Loss_D: 0.0208 Loss_G: 5.9109\n",
      "[0/25][277/782] Loss_D: 0.0666 Loss_G: 6.8145\n",
      "[0/25][278/782] Loss_D: 0.0377 Loss_G: 6.9185\n",
      "[0/25][279/782] Loss_D: 0.0541 Loss_G: 6.8906\n",
      "[0/25][280/782] Loss_D: 0.0812 Loss_G: 6.9008\n",
      "[0/25][281/782] Loss_D: 0.1266 Loss_G: 5.9729\n",
      "[0/25][282/782] Loss_D: 0.2522 Loss_G: 13.8615\n",
      "[0/25][283/782] Loss_D: 0.1116 Loss_G: 14.0140\n",
      "[0/25][284/782] Loss_D: 0.0348 Loss_G: 10.7313\n",
      "[0/25][285/782] Loss_D: 0.0592 Loss_G: 6.2589\n",
      "[0/25][286/782] Loss_D: 0.5940 Loss_G: 21.1981\n",
      "[0/25][287/782] Loss_D: 3.3274 Loss_G: 14.6483\n",
      "[0/25][288/782] Loss_D: 0.3391 Loss_G: 7.7218\n",
      "[0/25][289/782] Loss_D: 0.3033 Loss_G: 7.3675\n",
      "[0/25][290/782] Loss_D: 0.3989 Loss_G: 10.9370\n",
      "[0/25][291/782] Loss_D: 0.2083 Loss_G: 8.1540\n",
      "[0/25][292/782] Loss_D: 0.4204 Loss_G: 8.2696\n",
      "[0/25][293/782] Loss_D: 0.1958 Loss_G: 7.3298\n",
      "[0/25][294/782] Loss_D: 0.3779 Loss_G: 8.9927\n",
      "[0/25][295/782] Loss_D: 0.2984 Loss_G: 7.2841\n",
      "[0/25][296/782] Loss_D: 0.3701 Loss_G: 8.5687\n",
      "[0/25][297/782] Loss_D: 0.5120 Loss_G: 3.9301\n",
      "[0/25][298/782] Loss_D: 1.6985 Loss_G: 20.1458\n",
      "[0/25][299/782] Loss_D: 7.1744 Loss_G: 11.9619\n",
      "[0/25][300/782] Loss_D: 0.7752 Loss_G: 4.4311\n",
      "[0/25][301/782] Loss_D: 0.4804 Loss_G: 4.6233\n",
      "[0/25][302/782] Loss_D: 0.2844 Loss_G: 6.3523\n",
      "[0/25][303/782] Loss_D: 0.0514 Loss_G: 6.4461\n",
      "[0/25][304/782] Loss_D: 0.1790 Loss_G: 4.4711\n",
      "[0/25][305/782] Loss_D: 0.2412 Loss_G: 4.7901\n",
      "[0/25][306/782] Loss_D: 0.3400 Loss_G: 5.0690\n",
      "[0/25][307/782] Loss_D: 0.2224 Loss_G: 4.7251\n",
      "[0/25][308/782] Loss_D: 0.2288 Loss_G: 4.7052\n",
      "[0/25][309/782] Loss_D: 0.2121 Loss_G: 5.2854\n",
      "[0/25][310/782] Loss_D: 0.1514 Loss_G: 4.9281\n",
      "[0/25][311/782] Loss_D: 0.2362 Loss_G: 4.2557\n",
      "[0/25][312/782] Loss_D: 0.2760 Loss_G: 6.3577\n",
      "[0/25][313/782] Loss_D: 0.1947 Loss_G: 5.4790\n",
      "[0/25][314/782] Loss_D: 0.2060 Loss_G: 3.9969\n",
      "[0/25][315/782] Loss_D: 0.3124 Loss_G: 6.2690\n",
      "[0/25][316/782] Loss_D: 0.1794 Loss_G: 6.1472\n",
      "[0/25][317/782] Loss_D: 0.3200 Loss_G: 4.1444\n",
      "[0/25][318/782] Loss_D: 0.3167 Loss_G: 7.0926\n",
      "[0/25][319/782] Loss_D: 0.0822 Loss_G: 7.2614\n",
      "[0/25][320/782] Loss_D: 0.2429 Loss_G: 4.9425\n",
      "[0/25][321/782] Loss_D: 0.1119 Loss_G: 4.5593\n",
      "[0/25][322/782] Loss_D: 0.2334 Loss_G: 6.5076\n",
      "[0/25][323/782] Loss_D: 0.0666 Loss_G: 6.6149\n",
      "[0/25][324/782] Loss_D: 0.1450 Loss_G: 5.2709\n",
      "[0/25][325/782] Loss_D: 0.1243 Loss_G: 5.1051\n",
      "[0/25][326/782] Loss_D: 0.1057 Loss_G: 5.5866\n",
      "[0/25][327/782] Loss_D: 0.1944 Loss_G: 5.2016\n",
      "[0/25][328/782] Loss_D: 0.1089 Loss_G: 5.1794\n",
      "[0/25][329/782] Loss_D: 0.1454 Loss_G: 5.4070\n",
      "[0/25][330/782] Loss_D: 0.3100 Loss_G: 3.6046\n",
      "[0/25][331/782] Loss_D: 0.3115 Loss_G: 8.2612\n",
      "[0/25][332/782] Loss_D: 0.1387 Loss_G: 8.4909\n",
      "[0/25][333/782] Loss_D: 0.4500 Loss_G: 4.6146\n",
      "[0/25][334/782] Loss_D: 0.2183 Loss_G: 5.1012\n",
      "[0/25][335/782] Loss_D: 0.0946 Loss_G: 6.3414\n",
      "[0/25][336/782] Loss_D: 0.0748 Loss_G: 6.6163\n",
      "[0/25][337/782] Loss_D: 0.0728 Loss_G: 5.5272\n",
      "[0/25][338/782] Loss_D: 0.1386 Loss_G: 4.9088\n",
      "[0/25][339/782] Loss_D: 0.1893 Loss_G: 7.3682\n",
      "[0/25][340/782] Loss_D: 0.1055 Loss_G: 6.9337\n",
      "[0/25][341/782] Loss_D: 0.3028 Loss_G: 5.0821\n",
      "[0/25][342/782] Loss_D: 0.3547 Loss_G: 6.0681\n",
      "[0/25][343/782] Loss_D: 0.1580 Loss_G: 6.3738\n",
      "[0/25][344/782] Loss_D: 0.1536 Loss_G: 6.6405\n",
      "[0/25][345/782] Loss_D: 0.2294 Loss_G: 5.4528\n",
      "[0/25][346/782] Loss_D: 0.2090 Loss_G: 4.6502\n",
      "[0/25][347/782] Loss_D: 0.1732 Loss_G: 5.8345\n",
      "[0/25][348/782] Loss_D: 0.1567 Loss_G: 5.4318\n",
      "[0/25][349/782] Loss_D: 0.1493 Loss_G: 5.2539\n",
      "[0/25][350/782] Loss_D: 0.1656 Loss_G: 5.7634\n",
      "[0/25][351/782] Loss_D: 0.1283 Loss_G: 5.5766\n",
      "[0/25][352/782] Loss_D: 0.1989 Loss_G: 4.8148\n",
      "[0/25][353/782] Loss_D: 0.2337 Loss_G: 5.7210\n",
      "[0/25][354/782] Loss_D: 0.0992 Loss_G: 5.6002\n",
      "[0/25][355/782] Loss_D: 0.1092 Loss_G: 4.9735\n",
      "[0/25][356/782] Loss_D: 0.2052 Loss_G: 6.1356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/25][357/782] Loss_D: 0.2730 Loss_G: 4.3689\n",
      "[0/25][358/782] Loss_D: 0.2781 Loss_G: 7.9699\n",
      "[0/25][359/782] Loss_D: 0.4295 Loss_G: 4.9594\n",
      "[0/25][360/782] Loss_D: 0.2986 Loss_G: 6.1062\n",
      "[0/25][361/782] Loss_D: 0.2646 Loss_G: 4.6238\n",
      "[0/25][362/782] Loss_D: 0.1319 Loss_G: 5.5355\n",
      "[0/25][363/782] Loss_D: 0.1181 Loss_G: 5.5111\n",
      "[0/25][364/782] Loss_D: 0.2548 Loss_G: 4.4055\n",
      "[0/25][365/782] Loss_D: 0.3249 Loss_G: 7.1618\n",
      "[0/25][366/782] Loss_D: 0.3146 Loss_G: 4.0051\n",
      "[0/25][367/782] Loss_D: 0.4212 Loss_G: 7.0757\n",
      "[0/25][368/782] Loss_D: 0.2828 Loss_G: 4.9688\n",
      "[0/25][369/782] Loss_D: 0.3476 Loss_G: 7.7509\n",
      "[0/25][370/782] Loss_D: 0.2152 Loss_G: 5.7035\n",
      "[0/25][371/782] Loss_D: 0.2557 Loss_G: 5.3874\n",
      "[0/25][372/782] Loss_D: 0.2411 Loss_G: 6.0421\n",
      "[0/25][373/782] Loss_D: 0.7026 Loss_G: 0.9669\n",
      "[0/25][374/782] Loss_D: 2.0882 Loss_G: 15.8147\n",
      "[0/25][375/782] Loss_D: 3.9830 Loss_G: 9.4900\n",
      "[0/25][376/782] Loss_D: 0.3231 Loss_G: 5.4199\n",
      "[0/25][377/782] Loss_D: 1.4365 Loss_G: 5.4661\n",
      "[0/25][378/782] Loss_D: 0.9610 Loss_G: 4.7320\n",
      "[0/25][379/782] Loss_D: 1.0173 Loss_G: 3.2728\n",
      "[0/25][380/782] Loss_D: 1.1161 Loss_G: 7.2797\n",
      "[0/25][381/782] Loss_D: 1.3595 Loss_G: 3.6441\n",
      "[0/25][382/782] Loss_D: 1.0419 Loss_G: 4.1374\n",
      "[0/25][383/782] Loss_D: 0.7679 Loss_G: 3.4195\n",
      "[0/25][384/782] Loss_D: 0.7379 Loss_G: 5.3982\n",
      "[0/25][385/782] Loss_D: 0.8450 Loss_G: 2.6662\n",
      "[0/25][386/782] Loss_D: 0.6375 Loss_G: 4.2143\n",
      "[0/25][387/782] Loss_D: 0.4223 Loss_G: 4.1387\n",
      "[0/25][388/782] Loss_D: 0.2218 Loss_G: 4.0704\n",
      "[0/25][389/782] Loss_D: 0.4108 Loss_G: 3.3685\n",
      "[0/25][390/782] Loss_D: 0.4223 Loss_G: 4.5890\n",
      "[0/25][391/782] Loss_D: 0.4569 Loss_G: 3.6587\n",
      "[0/25][392/782] Loss_D: 0.2707 Loss_G: 4.3367\n",
      "[0/25][393/782] Loss_D: 0.3306 Loss_G: 4.0303\n",
      "[0/25][394/782] Loss_D: 0.5120 Loss_G: 2.7824\n",
      "[0/25][395/782] Loss_D: 0.5014 Loss_G: 5.7463\n",
      "[0/25][396/782] Loss_D: 0.6289 Loss_G: 3.1388\n",
      "[0/25][397/782] Loss_D: 0.3641 Loss_G: 3.8507\n",
      "[0/25][398/782] Loss_D: 0.4553 Loss_G: 4.9312\n",
      "[0/25][399/782] Loss_D: 0.4064 Loss_G: 3.3237\n",
      "[0/25][400/782] Loss_D: 0.3400 Loss_G: 4.2173\n",
      "[0/25][401/782] Loss_D: 0.3245 Loss_G: 4.0894\n",
      "[0/25][402/782] Loss_D: 0.2586 Loss_G: 4.0066\n",
      "[0/25][403/782] Loss_D: 0.4287 Loss_G: 4.3120\n",
      "[0/25][404/782] Loss_D: 0.3150 Loss_G: 4.7899\n",
      "[0/25][405/782] Loss_D: 0.3767 Loss_G: 2.5904\n",
      "[0/25][406/782] Loss_D: 0.8934 Loss_G: 7.1707\n",
      "[0/25][407/782] Loss_D: 1.1740 Loss_G: 1.6737\n",
      "[0/25][408/782] Loss_D: 1.6502 Loss_G: 9.4628\n",
      "[0/25][409/782] Loss_D: 1.9841 Loss_G: 3.4242\n",
      "[0/25][410/782] Loss_D: 0.3863 Loss_G: 3.8394\n",
      "[0/25][411/782] Loss_D: 0.5648 Loss_G: 6.6166\n",
      "[0/25][412/782] Loss_D: 1.0620 Loss_G: 0.9709\n",
      "[0/25][413/782] Loss_D: 2.0367 Loss_G: 10.7693\n",
      "[0/25][414/782] Loss_D: 3.8144 Loss_G: 4.7820\n",
      "[0/25][415/782] Loss_D: 0.7622 Loss_G: 1.5908\n",
      "[0/25][416/782] Loss_D: 1.2893 Loss_G: 5.2054\n",
      "[0/25][417/782] Loss_D: 1.2661 Loss_G: 2.9318\n",
      "[0/25][418/782] Loss_D: 0.5213 Loss_G: 2.3319\n",
      "[0/25][419/782] Loss_D: 0.4102 Loss_G: 3.8826\n",
      "[0/25][420/782] Loss_D: 0.3159 Loss_G: 3.8488\n",
      "[0/25][421/782] Loss_D: 0.2958 Loss_G: 3.4273\n",
      "[0/25][422/782] Loss_D: 0.4042 Loss_G: 3.9432\n",
      "[0/25][423/782] Loss_D: 0.6136 Loss_G: 2.8067\n",
      "[0/25][424/782] Loss_D: 0.8117 Loss_G: 6.6729\n",
      "[0/25][425/782] Loss_D: 0.5814 Loss_G: 4.6415\n",
      "[0/25][426/782] Loss_D: 0.5628 Loss_G: 3.8365\n",
      "[0/25][427/782] Loss_D: 0.5871 Loss_G: 5.1092\n",
      "[0/25][428/782] Loss_D: 0.6531 Loss_G: 4.2211\n",
      "[0/25][429/782] Loss_D: 0.7729 Loss_G: 3.6415\n",
      "[0/25][430/782] Loss_D: 0.8711 Loss_G: 6.1581\n",
      "[0/25][431/782] Loss_D: 0.6527 Loss_G: 3.1062\n",
      "[0/25][432/782] Loss_D: 0.5557 Loss_G: 5.9632\n",
      "[0/25][433/782] Loss_D: 0.6839 Loss_G: 3.4549\n",
      "[0/25][434/782] Loss_D: 0.6615 Loss_G: 7.2023\n",
      "[0/25][435/782] Loss_D: 0.6476 Loss_G: 4.0236\n",
      "[0/25][436/782] Loss_D: 0.8088 Loss_G: 5.6865\n",
      "[0/25][437/782] Loss_D: 0.9785 Loss_G: 2.5234\n",
      "[0/25][438/782] Loss_D: 1.1832 Loss_G: 9.3812\n",
      "[0/25][439/782] Loss_D: 2.4892 Loss_G: 2.9310\n",
      "[0/25][440/782] Loss_D: 0.8497 Loss_G: 5.0133\n",
      "[0/25][441/782] Loss_D: 0.6021 Loss_G: 4.8291\n",
      "[0/25][442/782] Loss_D: 0.9969 Loss_G: 3.1115\n",
      "[0/25][443/782] Loss_D: 0.8120 Loss_G: 6.8316\n",
      "[0/25][444/782] Loss_D: 0.9391 Loss_G: 1.8152\n",
      "[0/25][445/782] Loss_D: 1.2104 Loss_G: 7.7650\n",
      "[0/25][446/782] Loss_D: 1.0324 Loss_G: 3.8971\n",
      "[0/25][447/782] Loss_D: 0.3817 Loss_G: 2.4896\n",
      "[0/25][448/782] Loss_D: 0.7694 Loss_G: 5.7334\n",
      "[0/25][449/782] Loss_D: 0.6795 Loss_G: 3.3937\n",
      "[0/25][450/782] Loss_D: 0.6011 Loss_G: 3.0425\n",
      "[0/25][451/782] Loss_D: 0.7844 Loss_G: 5.4459\n",
      "[0/25][452/782] Loss_D: 0.9574 Loss_G: 2.4451\n",
      "[0/25][453/782] Loss_D: 0.9994 Loss_G: 6.5587\n",
      "[0/25][454/782] Loss_D: 1.2557 Loss_G: 2.4769\n",
      "[0/25][455/782] Loss_D: 0.6581 Loss_G: 5.0203\n",
      "[0/25][456/782] Loss_D: 0.3799 Loss_G: 4.9193\n",
      "[0/25][457/782] Loss_D: 0.4851 Loss_G: 3.2680\n",
      "[0/25][458/782] Loss_D: 0.9966 Loss_G: 7.1632\n",
      "[0/25][459/782] Loss_D: 1.3047 Loss_G: 2.9306\n",
      "[0/25][460/782] Loss_D: 0.8090 Loss_G: 4.9804\n",
      "[0/25][461/782] Loss_D: 0.2905 Loss_G: 5.6849\n",
      "[0/25][462/782] Loss_D: 0.2912 Loss_G: 5.7927\n",
      "[0/25][463/782] Loss_D: 0.3352 Loss_G: 4.6761\n",
      "[0/25][464/782] Loss_D: 0.6435 Loss_G: 4.4817\n",
      "[0/25][465/782] Loss_D: 0.3201 Loss_G: 4.4421\n",
      "[0/25][466/782] Loss_D: 0.2910 Loss_G: 6.6536\n",
      "[0/25][467/782] Loss_D: 0.2116 Loss_G: 4.8271\n",
      "[0/25][468/782] Loss_D: 0.2659 Loss_G: 5.7978\n",
      "[0/25][469/782] Loss_D: 0.1974 Loss_G: 3.8449\n",
      "[0/25][470/782] Loss_D: 0.5352 Loss_G: 7.5444\n",
      "[0/25][471/782] Loss_D: 0.7803 Loss_G: 2.5866\n",
      "[0/25][472/782] Loss_D: 1.1119 Loss_G: 12.8304\n",
      "[0/25][473/782] Loss_D: 2.1499 Loss_G: 3.4517\n",
      "[0/25][474/782] Loss_D: 1.0880 Loss_G: 8.7463\n",
      "[0/25][475/782] Loss_D: 1.2621 Loss_G: 2.4554\n",
      "[0/25][476/782] Loss_D: 0.7532 Loss_G: 4.8436\n",
      "[0/25][477/782] Loss_D: 0.2951 Loss_G: 4.7353\n",
      "[0/25][478/782] Loss_D: 0.3381 Loss_G: 3.6797\n",
      "[0/25][479/782] Loss_D: 0.3471 Loss_G: 4.5248\n",
      "[0/25][480/782] Loss_D: 0.2490 Loss_G: 4.5343\n",
      "[0/25][481/782] Loss_D: 0.2558 Loss_G: 4.4081\n",
      "[0/25][482/782] Loss_D: 0.2492 Loss_G: 3.8873\n",
      "[0/25][483/782] Loss_D: 0.1793 Loss_G: 4.4293\n",
      "[0/25][484/782] Loss_D: 0.1019 Loss_G: 4.8690\n",
      "[0/25][485/782] Loss_D: 0.1265 Loss_G: 4.4884\n",
      "[0/25][486/782] Loss_D: 0.2511 Loss_G: 3.7901\n",
      "[0/25][487/782] Loss_D: 0.2652 Loss_G: 6.1968\n",
      "[0/25][488/782] Loss_D: 0.3347 Loss_G: 4.0947\n",
      "[0/25][489/782] Loss_D: 0.1695 Loss_G: 5.4741\n",
      "[0/25][490/782] Loss_D: 0.2257 Loss_G: 4.1340\n",
      "[0/25][491/782] Loss_D: 0.2801 Loss_G: 7.4052\n",
      "[0/25][492/782] Loss_D: 0.2629 Loss_G: 5.9219\n",
      "[0/25][493/782] Loss_D: 0.2647 Loss_G: 3.0728\n",
      "[0/25][494/782] Loss_D: 0.5054 Loss_G: 7.7244\n",
      "[0/25][495/782] Loss_D: 0.3321 Loss_G: 6.2489\n",
      "[0/25][496/782] Loss_D: 0.3173 Loss_G: 3.3506\n",
      "[0/25][497/782] Loss_D: 0.3791 Loss_G: 4.7854\n",
      "[0/25][498/782] Loss_D: 0.2082 Loss_G: 5.1488\n",
      "[0/25][499/782] Loss_D: 0.1576 Loss_G: 4.5736\n",
      "[0/25][500/782] Loss_D: 0.2099 Loss_G: 4.5693\n",
      "[0/25][501/782] Loss_D: 0.2565 Loss_G: 4.4823\n",
      "[0/25][502/782] Loss_D: 0.4246 Loss_G: 3.4325\n",
      "[0/25][503/782] Loss_D: 0.3573 Loss_G: 6.0072\n",
      "[0/25][504/782] Loss_D: 0.2173 Loss_G: 5.2736\n",
      "[0/25][505/782] Loss_D: 0.2130 Loss_G: 4.5986\n",
      "[0/25][506/782] Loss_D: 0.3523 Loss_G: 5.9215\n",
      "[0/25][507/782] Loss_D: 0.3663 Loss_G: 3.8488\n",
      "[0/25][508/782] Loss_D: 1.0576 Loss_G: 10.0420\n",
      "[0/25][509/782] Loss_D: 1.4891 Loss_G: 3.1608\n",
      "[0/25][510/782] Loss_D: 1.0330 Loss_G: 10.2302\n",
      "[0/25][511/782] Loss_D: 0.6731 Loss_G: 6.7661\n",
      "[0/25][512/782] Loss_D: 0.2042 Loss_G: 4.5445\n",
      "[0/25][513/782] Loss_D: 0.6312 Loss_G: 8.2048\n",
      "[0/25][514/782] Loss_D: 0.5667 Loss_G: 4.5811\n",
      "[0/25][515/782] Loss_D: 0.8562 Loss_G: 7.0348\n",
      "[0/25][516/782] Loss_D: 0.3902 Loss_G: 4.1904\n",
      "[0/25][517/782] Loss_D: 0.8109 Loss_G: 7.3361\n",
      "[0/25][518/782] Loss_D: 0.4800 Loss_G: 4.8610\n",
      "[0/25][519/782] Loss_D: 0.6974 Loss_G: 6.3745\n",
      "[0/25][520/782] Loss_D: 0.4267 Loss_G: 3.3898\n",
      "[0/25][521/782] Loss_D: 0.3920 Loss_G: 7.7759\n",
      "[0/25][522/782] Loss_D: 0.4755 Loss_G: 3.3770\n",
      "[0/25][523/782] Loss_D: 1.0592 Loss_G: 11.2387\n",
      "[0/25][524/782] Loss_D: 1.6668 Loss_G: 4.8310\n",
      "[0/25][525/782] Loss_D: 0.4251 Loss_G: 6.2837\n",
      "[0/25][526/782] Loss_D: 0.3227 Loss_G: 5.7497\n",
      "[0/25][527/782] Loss_D: 0.2200 Loss_G: 5.4053\n",
      "[0/25][528/782] Loss_D: 0.1988 Loss_G: 5.6774\n",
      "[0/25][529/782] Loss_D: 0.4185 Loss_G: 2.8450\n",
      "[0/25][530/782] Loss_D: 0.8818 Loss_G: 13.8012\n",
      "[0/25][531/782] Loss_D: 2.1764 Loss_G: 9.0873\n",
      "[0/25][532/782] Loss_D: 0.1675 Loss_G: 3.8505\n",
      "[0/25][533/782] Loss_D: 0.5191 Loss_G: 6.7784\n",
      "[0/25][534/782] Loss_D: 0.1391 Loss_G: 6.5034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/25][535/782] Loss_D: 0.2057 Loss_G: 4.6236\n",
      "[0/25][536/782] Loss_D: 0.2835 Loss_G: 4.3422\n",
      "[0/25][537/782] Loss_D: 0.2799 Loss_G: 6.3989\n",
      "[0/25][538/782] Loss_D: 0.1620 Loss_G: 6.3052\n",
      "[0/25][539/782] Loss_D: 0.1148 Loss_G: 4.4559\n",
      "[0/25][540/782] Loss_D: 0.2193 Loss_G: 5.4018\n",
      "[0/25][541/782] Loss_D: 0.2051 Loss_G: 4.6353\n",
      "[0/25][542/782] Loss_D: 0.1424 Loss_G: 4.6438\n",
      "[0/25][543/782] Loss_D: 0.6276 Loss_G: 6.3534\n",
      "[0/25][544/782] Loss_D: 0.4664 Loss_G: 4.1599\n",
      "[0/25][545/782] Loss_D: 0.4961 Loss_G: 7.0047\n",
      "[0/25][546/782] Loss_D: 0.4539 Loss_G: 5.1596\n",
      "[0/25][547/782] Loss_D: 0.2962 Loss_G: 5.0169\n",
      "[0/25][548/782] Loss_D: 0.2751 Loss_G: 6.0295\n",
      "[0/25][549/782] Loss_D: 0.1363 Loss_G: 5.7649\n",
      "[0/25][550/782] Loss_D: 0.2844 Loss_G: 6.2926\n",
      "[0/25][551/782] Loss_D: 0.1605 Loss_G: 5.7823\n",
      "[0/25][552/782] Loss_D: 0.1357 Loss_G: 4.9538\n",
      "[0/25][553/782] Loss_D: 0.4266 Loss_G: 9.2649\n",
      "[0/25][554/782] Loss_D: 0.3040 Loss_G: 7.2221\n",
      "[0/25][555/782] Loss_D: 0.1108 Loss_G: 4.1928\n",
      "[0/25][556/782] Loss_D: 0.3759 Loss_G: 9.7114\n",
      "[0/25][557/782] Loss_D: 0.1482 Loss_G: 8.6199\n",
      "[0/25][558/782] Loss_D: 0.2035 Loss_G: 4.9571\n",
      "[0/25][559/782] Loss_D: 0.9416 Loss_G: 14.3731\n",
      "[0/25][560/782] Loss_D: 1.9193 Loss_G: 8.9790\n",
      "[0/25][561/782] Loss_D: 0.2485 Loss_G: 4.3168\n",
      "[0/25][562/782] Loss_D: 0.9383 Loss_G: 11.5796\n",
      "[0/25][563/782] Loss_D: 0.2437 Loss_G: 8.6845\n",
      "[0/25][564/782] Loss_D: 0.2805 Loss_G: 5.1724\n",
      "[0/25][565/782] Loss_D: 2.1782 Loss_G: 15.9063\n",
      "[0/25][566/782] Loss_D: 4.0590 Loss_G: 6.6698\n",
      "[0/25][567/782] Loss_D: 1.1748 Loss_G: 2.7015\n",
      "[0/25][568/782] Loss_D: 2.5038 Loss_G: 12.3704\n",
      "[0/25][569/782] Loss_D: 3.5034 Loss_G: 6.7219\n",
      "[0/25][570/782] Loss_D: 0.3898 Loss_G: 3.0150\n",
      "[0/25][571/782] Loss_D: 1.3563 Loss_G: 7.0062\n",
      "[0/25][572/782] Loss_D: 0.5605 Loss_G: 5.9489\n",
      "[0/25][573/782] Loss_D: 0.3810 Loss_G: 3.3294\n",
      "[0/25][574/782] Loss_D: 0.8140 Loss_G: 4.5619\n",
      "[0/25][575/782] Loss_D: 0.5883 Loss_G: 3.9394\n",
      "[0/25][576/782] Loss_D: 0.5639 Loss_G: 3.8865\n",
      "[0/25][577/782] Loss_D: 0.8280 Loss_G: 2.7071\n",
      "[0/25][578/782] Loss_D: 0.5646 Loss_G: 4.1652\n",
      "[0/25][579/782] Loss_D: 0.2791 Loss_G: 4.4657\n",
      "[0/25][580/782] Loss_D: 0.2855 Loss_G: 3.9356\n",
      "[0/25][581/782] Loss_D: 0.3822 Loss_G: 2.9791\n",
      "[0/25][582/782] Loss_D: 0.3924 Loss_G: 4.1279\n",
      "[0/25][583/782] Loss_D: 0.1873 Loss_G: 4.3370\n",
      "[0/25][584/782] Loss_D: 0.4083 Loss_G: 2.6336\n",
      "[0/25][585/782] Loss_D: 0.3893 Loss_G: 3.6436\n",
      "[0/25][586/782] Loss_D: 0.3332 Loss_G: 3.6912\n",
      "[0/25][587/782] Loss_D: 0.2743 Loss_G: 3.6081\n",
      "[0/25][588/782] Loss_D: 0.3131 Loss_G: 3.3610\n",
      "[0/25][589/782] Loss_D: 0.2602 Loss_G: 3.2909\n",
      "[0/25][590/782] Loss_D: 0.2574 Loss_G: 4.0650\n",
      "[0/25][591/782] Loss_D: 0.4547 Loss_G: 2.3495\n",
      "[0/25][592/782] Loss_D: 0.4392 Loss_G: 3.9179\n",
      "[0/25][593/782] Loss_D: 0.3484 Loss_G: 3.9007\n",
      "[0/25][594/782] Loss_D: 0.2438 Loss_G: 3.4003\n",
      "[0/25][595/782] Loss_D: 0.2886 Loss_G: 3.2482\n",
      "[0/25][596/782] Loss_D: 0.3048 Loss_G: 4.3290\n",
      "[0/25][597/782] Loss_D: 0.1987 Loss_G: 5.1079\n",
      "[0/25][598/782] Loss_D: 0.8387 Loss_G: 1.0219\n",
      "[0/25][599/782] Loss_D: 1.3129 Loss_G: 8.7099\n",
      "[0/25][600/782] Loss_D: 0.9818 Loss_G: 6.4529\n",
      "[0/25][601/782] Loss_D: 0.0557 Loss_G: 4.5472\n",
      "[0/25][602/782] Loss_D: 0.2255 Loss_G: 3.5857\n",
      "[0/25][603/782] Loss_D: 0.3606 Loss_G: 4.7805\n",
      "[0/25][604/782] Loss_D: 0.2512 Loss_G: 4.6503\n",
      "[0/25][605/782] Loss_D: 0.2030 Loss_G: 4.0258\n",
      "[0/25][606/782] Loss_D: 0.2678 Loss_G: 3.9122\n",
      "[0/25][607/782] Loss_D: 0.4944 Loss_G: 6.3420\n",
      "[0/25][608/782] Loss_D: 1.1751 Loss_G: 1.9228\n",
      "[0/25][609/782] Loss_D: 1.1949 Loss_G: 8.6575\n",
      "[0/25][610/782] Loss_D: 0.6760 Loss_G: 7.8480\n",
      "[0/25][611/782] Loss_D: 0.1742 Loss_G: 4.2183\n",
      "[0/25][612/782] Loss_D: 0.2087 Loss_G: 3.5519\n",
      "[0/25][613/782] Loss_D: 0.2202 Loss_G: 5.1128\n",
      "[0/25][614/782] Loss_D: 0.0748 Loss_G: 5.4719\n",
      "[0/25][615/782] Loss_D: 0.1267 Loss_G: 4.6757\n",
      "[0/25][616/782] Loss_D: 0.3440 Loss_G: 4.4185\n",
      "[0/25][617/782] Loss_D: 0.9938 Loss_G: 1.5087\n",
      "[0/25][618/782] Loss_D: 1.7470 Loss_G: 9.7649\n",
      "[0/25][619/782] Loss_D: 2.1169 Loss_G: 6.1534\n",
      "[0/25][620/782] Loss_D: 0.1566 Loss_G: 2.0262\n",
      "[0/25][621/782] Loss_D: 0.7490 Loss_G: 7.4606\n",
      "[0/25][622/782] Loss_D: 0.3554 Loss_G: 5.8330\n",
      "[0/25][623/782] Loss_D: 0.2458 Loss_G: 3.5734\n",
      "[0/25][624/782] Loss_D: 0.3591 Loss_G: 4.4118\n",
      "[0/25][625/782] Loss_D: 0.5052 Loss_G: 4.6197\n",
      "[0/25][626/782] Loss_D: 0.4897 Loss_G: 3.3200\n",
      "[0/25][627/782] Loss_D: 0.8603 Loss_G: 6.1102\n",
      "[0/25][628/782] Loss_D: 0.6702 Loss_G: 4.1452\n",
      "[0/25][629/782] Loss_D: 0.5186 Loss_G: 4.0977\n",
      "[0/25][630/782] Loss_D: 0.3133 Loss_G: 4.6365\n",
      "[0/25][631/782] Loss_D: 0.2895 Loss_G: 4.2140\n",
      "[0/25][632/782] Loss_D: 0.4739 Loss_G: 3.1818\n",
      "[0/25][633/782] Loss_D: 0.7395 Loss_G: 5.0520\n",
      "[0/25][634/782] Loss_D: 0.4514 Loss_G: 4.2828\n",
      "[0/25][635/782] Loss_D: 0.5338 Loss_G: 4.3176\n",
      "[0/25][636/782] Loss_D: 0.3184 Loss_G: 5.2935\n",
      "[0/25][637/782] Loss_D: 0.2883 Loss_G: 4.5508\n",
      "[0/25][638/782] Loss_D: 0.9292 Loss_G: 7.7247\n",
      "[0/25][639/782] Loss_D: 0.5061 Loss_G: 6.3295\n",
      "[0/25][640/782] Loss_D: 0.5011 Loss_G: 3.2963\n",
      "[0/25][641/782] Loss_D: 0.7675 Loss_G: 11.1538\n",
      "[0/25][642/782] Loss_D: 0.2244 Loss_G: 11.4953\n",
      "[0/25][643/782] Loss_D: 0.2894 Loss_G: 7.5326\n",
      "[0/25][644/782] Loss_D: 0.0711 Loss_G: 4.0509\n",
      "[0/25][645/782] Loss_D: 0.3570 Loss_G: 5.7687\n",
      "[0/25][646/782] Loss_D: 0.1141 Loss_G: 6.4517\n",
      "[0/25][647/782] Loss_D: 0.2368 Loss_G: 5.2213\n",
      "[0/25][648/782] Loss_D: 0.2882 Loss_G: 4.2578\n",
      "[0/25][649/782] Loss_D: 0.4167 Loss_G: 5.7039\n",
      "[0/25][650/782] Loss_D: 0.4283 Loss_G: 4.7334\n",
      "[0/25][651/782] Loss_D: 0.2028 Loss_G: 5.0675\n",
      "[0/25][652/782] Loss_D: 0.2201 Loss_G: 4.8848\n",
      "[0/25][653/782] Loss_D: 0.1972 Loss_G: 4.8181\n",
      "[0/25][654/782] Loss_D: 0.3427 Loss_G: 3.7859\n",
      "[0/25][655/782] Loss_D: 0.2800 Loss_G: 5.2655\n",
      "[0/25][656/782] Loss_D: 0.1878 Loss_G: 4.7289\n",
      "[0/25][657/782] Loss_D: 0.1494 Loss_G: 4.0803\n",
      "[0/25][658/782] Loss_D: 0.3144 Loss_G: 5.5637\n",
      "[0/25][659/782] Loss_D: 0.3427 Loss_G: 4.3869\n",
      "[0/25][660/782] Loss_D: 0.2283 Loss_G: 4.1136\n",
      "[0/25][661/782] Loss_D: 0.2728 Loss_G: 5.3683\n",
      "[0/25][662/782] Loss_D: 0.1809 Loss_G: 5.6419\n",
      "[0/25][663/782] Loss_D: 0.3976 Loss_G: 3.5802\n",
      "[0/25][664/782] Loss_D: 0.1939 Loss_G: 5.2404\n",
      "[0/25][665/782] Loss_D: 0.2929 Loss_G: 5.2836\n",
      "[0/25][666/782] Loss_D: 0.2875 Loss_G: 4.0272\n",
      "[0/25][667/782] Loss_D: 0.3009 Loss_G: 6.0055\n",
      "[0/25][668/782] Loss_D: 0.2349 Loss_G: 4.3531\n",
      "[0/25][669/782] Loss_D: 0.2703 Loss_G: 5.6242\n",
      "[0/25][670/782] Loss_D: 0.1311 Loss_G: 5.1202\n",
      "[0/25][671/782] Loss_D: 0.1229 Loss_G: 5.6292\n",
      "[0/25][672/782] Loss_D: 0.1405 Loss_G: 4.9376\n",
      "[0/25][673/782] Loss_D: 0.2321 Loss_G: 4.0352\n",
      "[0/25][674/782] Loss_D: 0.6217 Loss_G: 12.3826\n",
      "[0/25][675/782] Loss_D: 1.6728 Loss_G: 1.4176\n",
      "[0/25][676/782] Loss_D: 2.0154 Loss_G: 11.9615\n",
      "[0/25][677/782] Loss_D: 3.5750 Loss_G: 1.2342\n",
      "[0/25][678/782] Loss_D: 2.1287 Loss_G: 5.2947\n",
      "[0/25][679/782] Loss_D: 0.3400 Loss_G: 5.4834\n",
      "[0/25][680/782] Loss_D: 0.4751 Loss_G: 3.4011\n",
      "[0/25][681/782] Loss_D: 0.7191 Loss_G: 3.3116\n",
      "[0/25][682/782] Loss_D: 0.6763 Loss_G: 4.3346\n",
      "[0/25][683/782] Loss_D: 0.8167 Loss_G: 2.7888\n",
      "[0/25][684/782] Loss_D: 0.9130 Loss_G: 5.0532\n",
      "[0/25][685/782] Loss_D: 0.6626 Loss_G: 3.4052\n",
      "[0/25][686/782] Loss_D: 0.8506 Loss_G: 5.4372\n",
      "[0/25][687/782] Loss_D: 0.4648 Loss_G: 3.8290\n",
      "[0/25][688/782] Loss_D: 0.5737 Loss_G: 2.1519\n",
      "[0/25][689/782] Loss_D: 0.9570 Loss_G: 7.3660\n",
      "[0/25][690/782] Loss_D: 1.0123 Loss_G: 3.9668\n",
      "[0/25][691/782] Loss_D: 0.4882 Loss_G: 2.9930\n",
      "[0/25][692/782] Loss_D: 0.5790 Loss_G: 5.7951\n",
      "[0/25][693/782] Loss_D: 0.3678 Loss_G: 5.5094\n",
      "[0/25][694/782] Loss_D: 0.4571 Loss_G: 3.5317\n",
      "[0/25][695/782] Loss_D: 0.9639 Loss_G: 6.9510\n",
      "[0/25][696/782] Loss_D: 1.6828 Loss_G: 2.0812\n",
      "[0/25][697/782] Loss_D: 1.4484 Loss_G: 7.7535\n",
      "[0/25][698/782] Loss_D: 0.9347 Loss_G: 5.1851\n",
      "[0/25][699/782] Loss_D: 0.1867 Loss_G: 3.6016\n",
      "[0/25][700/782] Loss_D: 0.6003 Loss_G: 5.9354\n",
      "[0/25][701/782] Loss_D: 0.1729 Loss_G: 6.1025\n",
      "[0/25][702/782] Loss_D: 0.4190 Loss_G: 3.5394\n",
      "[0/25][703/782] Loss_D: 0.5891 Loss_G: 6.1522\n",
      "[0/25][704/782] Loss_D: 0.5113 Loss_G: 4.7963\n",
      "[0/25][705/782] Loss_D: 0.1575 Loss_G: 4.0987\n",
      "[0/25][706/782] Loss_D: 0.3625 Loss_G: 4.5786\n",
      "[0/25][707/782] Loss_D: 0.5321 Loss_G: 3.3036\n",
      "[0/25][708/782] Loss_D: 0.4984 Loss_G: 5.2931\n",
      "[0/25][709/782] Loss_D: 0.2405 Loss_G: 4.5844\n",
      "[0/25][710/782] Loss_D: 0.2677 Loss_G: 3.3951\n",
      "[0/25][711/782] Loss_D: 0.4277 Loss_G: 4.3774\n",
      "[0/25][712/782] Loss_D: 0.4113 Loss_G: 3.6518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/25][713/782] Loss_D: 0.3768 Loss_G: 4.2947\n",
      "[0/25][714/782] Loss_D: 0.4436 Loss_G: 4.6819\n",
      "[0/25][715/782] Loss_D: 0.2732 Loss_G: 4.3443\n",
      "[0/25][716/782] Loss_D: 0.6236 Loss_G: 7.6169\n",
      "[0/25][717/782] Loss_D: 0.5619 Loss_G: 3.9060\n",
      "[0/25][718/782] Loss_D: 0.5697 Loss_G: 5.7930\n",
      "[0/25][719/782] Loss_D: 0.7381 Loss_G: 5.2585\n",
      "[0/25][720/782] Loss_D: 0.3269 Loss_G: 4.3693\n",
      "[0/25][721/782] Loss_D: 0.3691 Loss_G: 6.5324\n",
      "[0/25][722/782] Loss_D: 0.0841 Loss_G: 6.6565\n",
      "[0/25][723/782] Loss_D: 0.2299 Loss_G: 4.6234\n",
      "[0/25][724/782] Loss_D: 0.3273 Loss_G: 6.0279\n",
      "[0/25][725/782] Loss_D: 0.2040 Loss_G: 5.3223\n",
      "[0/25][726/782] Loss_D: 0.2980 Loss_G: 7.0663\n",
      "[0/25][727/782] Loss_D: 0.3458 Loss_G: 4.2558\n",
      "[0/25][728/782] Loss_D: 0.4164 Loss_G: 8.3841\n",
      "[0/25][729/782] Loss_D: 0.3989 Loss_G: 4.7927\n",
      "[0/25][730/782] Loss_D: 0.3908 Loss_G: 7.8424\n",
      "[0/25][731/782] Loss_D: 0.4097 Loss_G: 4.8214\n",
      "[0/25][732/782] Loss_D: 0.2618 Loss_G: 5.4162\n",
      "[0/25][733/782] Loss_D: 0.2732 Loss_G: 5.6725\n",
      "[0/25][734/782] Loss_D: 0.2968 Loss_G: 4.7500\n",
      "[0/25][735/782] Loss_D: 0.2592 Loss_G: 4.6070\n",
      "[0/25][736/782] Loss_D: 0.3431 Loss_G: 3.8830\n",
      "[0/25][737/782] Loss_D: 0.3749 Loss_G: 6.3817\n",
      "[0/25][738/782] Loss_D: 0.7154 Loss_G: 1.9609\n",
      "[0/25][739/782] Loss_D: 1.1775 Loss_G: 11.2780\n",
      "[0/25][740/782] Loss_D: 0.8428 Loss_G: 4.6088\n",
      "[0/25][741/782] Loss_D: 0.6063 Loss_G: 6.7449\n",
      "[0/25][742/782] Loss_D: 0.2870 Loss_G: 5.2794\n",
      "[0/25][743/782] Loss_D: 0.3340 Loss_G: 5.2597\n",
      "[0/25][744/782] Loss_D: 0.2754 Loss_G: 5.7410\n",
      "[0/25][745/782] Loss_D: 0.2886 Loss_G: 4.4092\n",
      "[0/25][746/782] Loss_D: 0.3315 Loss_G: 5.8410\n",
      "[0/25][747/782] Loss_D: 0.1778 Loss_G: 5.4822\n",
      "[0/25][748/782] Loss_D: 0.2254 Loss_G: 4.5126\n",
      "[0/25][749/782] Loss_D: 0.3917 Loss_G: 7.9281\n",
      "[0/25][750/782] Loss_D: 1.0765 Loss_G: 2.1609\n",
      "[0/25][751/782] Loss_D: 0.9047 Loss_G: 9.0183\n",
      "[0/25][752/782] Loss_D: 0.4752 Loss_G: 6.8885\n",
      "[0/25][753/782] Loss_D: 0.2305 Loss_G: 4.7993\n",
      "[0/25][754/782] Loss_D: 1.0089 Loss_G: 11.5579\n",
      "[0/25][755/782] Loss_D: 1.6530 Loss_G: 5.4020\n",
      "[0/25][756/782] Loss_D: 0.2718 Loss_G: 3.0220\n",
      "[0/25][757/782] Loss_D: 0.5939 Loss_G: 6.2766\n",
      "[0/25][758/782] Loss_D: 0.3511 Loss_G: 5.4367\n",
      "[0/25][759/782] Loss_D: 0.3077 Loss_G: 3.4887\n",
      "[0/25][760/782] Loss_D: 0.2679 Loss_G: 3.5234\n",
      "[0/25][761/782] Loss_D: 0.2548 Loss_G: 4.8076\n",
      "[0/25][762/782] Loss_D: 0.2491 Loss_G: 3.6542\n",
      "[0/25][763/782] Loss_D: 0.2253 Loss_G: 4.3889\n",
      "[0/25][764/782] Loss_D: 0.1667 Loss_G: 4.3598\n",
      "[0/25][765/782] Loss_D: 0.2080 Loss_G: 4.1127\n",
      "[0/25][766/782] Loss_D: 0.2610 Loss_G: 5.7050\n",
      "[0/25][767/782] Loss_D: 0.3656 Loss_G: 3.4026\n",
      "[0/25][768/782] Loss_D: 0.4395 Loss_G: 5.8460\n",
      "[0/25][769/782] Loss_D: 0.1531 Loss_G: 5.5802\n",
      "[0/25][770/782] Loss_D: 0.1232 Loss_G: 4.5165\n",
      "[0/25][771/782] Loss_D: 0.2333 Loss_G: 4.9769\n",
      "[0/25][772/782] Loss_D: 0.2683 Loss_G: 5.4891\n",
      "[0/25][773/782] Loss_D: 0.3200 Loss_G: 3.9143\n",
      "[0/25][774/782] Loss_D: 0.3060 Loss_G: 6.7305\n",
      "[0/25][775/782] Loss_D: 0.2260 Loss_G: 5.1534\n",
      "[0/25][776/782] Loss_D: 0.1365 Loss_G: 3.8135\n",
      "[0/25][777/782] Loss_D: 0.1314 Loss_G: 5.0945\n",
      "[0/25][778/782] Loss_D: 0.1848 Loss_G: 4.2136\n",
      "[0/25][779/782] Loss_D: 0.2987 Loss_G: 5.6282\n",
      "[0/25][780/782] Loss_D: 0.4150 Loss_G: 2.2157\n",
      "[0/25][781/782] Loss_D: 0.2645 Loss_G: 4.7983\n",
      "[1/25][0/782] Loss_D: 0.7424 Loss_G: 11.6646\n",
      "[1/25][1/782] Loss_D: 1.6143 Loss_G: 7.0012\n",
      "[1/25][2/782] Loss_D: 0.6270 Loss_G: 0.9684\n",
      "[1/25][3/782] Loss_D: 2.0321 Loss_G: 10.7897\n",
      "[1/25][4/782] Loss_D: 0.5670 Loss_G: 10.1851\n",
      "[1/25][5/782] Loss_D: 0.2841 Loss_G: 7.7061\n",
      "[1/25][6/782] Loss_D: 0.2198 Loss_G: 3.8450\n",
      "[1/25][7/782] Loss_D: 0.4681 Loss_G: 4.9463\n",
      "[1/25][8/782] Loss_D: 0.6029 Loss_G: 4.6949\n",
      "[1/25][9/782] Loss_D: 0.4454 Loss_G: 5.0303\n",
      "[1/25][10/782] Loss_D: 0.5033 Loss_G: 3.0061\n",
      "[1/25][11/782] Loss_D: 0.4799 Loss_G: 5.8689\n",
      "[1/25][12/782] Loss_D: 0.1599 Loss_G: 5.6155\n",
      "[1/25][13/782] Loss_D: 0.3115 Loss_G: 3.5813\n",
      "[1/25][14/782] Loss_D: 0.4457 Loss_G: 5.6389\n",
      "[1/25][15/782] Loss_D: 0.1913 Loss_G: 5.6957\n",
      "[1/25][16/782] Loss_D: 0.4908 Loss_G: 3.2085\n",
      "[1/25][17/782] Loss_D: 0.8259 Loss_G: 9.5210\n",
      "[1/25][18/782] Loss_D: 1.1415 Loss_G: 6.4607\n",
      "[1/25][19/782] Loss_D: 0.0971 Loss_G: 3.9624\n",
      "[1/25][20/782] Loss_D: 0.1751 Loss_G: 4.2735\n",
      "[1/25][21/782] Loss_D: 0.2363 Loss_G: 6.0323\n",
      "[1/25][22/782] Loss_D: 0.1476 Loss_G: 5.8283\n",
      "[1/25][23/782] Loss_D: 0.1481 Loss_G: 4.3118\n",
      "[1/25][24/782] Loss_D: 0.3839 Loss_G: 6.1438\n",
      "[1/25][25/782] Loss_D: 0.5044 Loss_G: 3.7739\n",
      "[1/25][26/782] Loss_D: 0.4697 Loss_G: 4.3550\n",
      "[1/25][27/782] Loss_D: 0.5050 Loss_G: 4.4228\n",
      "[1/25][28/782] Loss_D: 0.1743 Loss_G: 4.4854\n",
      "[1/25][29/782] Loss_D: 0.5369 Loss_G: 7.6261\n",
      "[1/25][30/782] Loss_D: 0.7260 Loss_G: 3.2691\n",
      "[1/25][31/782] Loss_D: 0.6183 Loss_G: 5.8405\n",
      "[1/25][32/782] Loss_D: 0.2305 Loss_G: 6.0089\n",
      "[1/25][33/782] Loss_D: 0.5709 Loss_G: 2.8074\n",
      "[1/25][34/782] Loss_D: 0.7166 Loss_G: 8.3781\n",
      "[1/25][35/782] Loss_D: 0.9623 Loss_G: 3.7748\n",
      "[1/25][36/782] Loss_D: 0.5843 Loss_G: 7.0824\n",
      "[1/25][37/782] Loss_D: 0.0985 Loss_G: 6.8447\n",
      "[1/25][38/782] Loss_D: 0.2561 Loss_G: 6.5233\n",
      "[1/25][39/782] Loss_D: 0.5284 Loss_G: 4.3670\n",
      "[1/25][40/782] Loss_D: 0.8067 Loss_G: 10.9726\n",
      "[1/25][41/782] Loss_D: 0.8680 Loss_G: 9.7140\n",
      "[1/25][42/782] Loss_D: 0.3245 Loss_G: 3.3402\n",
      "[1/25][43/782] Loss_D: 0.5806 Loss_G: 8.1071\n",
      "[1/25][44/782] Loss_D: 0.1678 Loss_G: 7.4657\n",
      "[1/25][45/782] Loss_D: 0.3184 Loss_G: 6.0235\n",
      "[1/25][46/782] Loss_D: 0.3577 Loss_G: 5.2523\n",
      "[1/25][47/782] Loss_D: 0.3059 Loss_G: 7.4282\n",
      "[1/25][48/782] Loss_D: 0.4563 Loss_G: 4.8856\n",
      "[1/25][49/782] Loss_D: 0.4309 Loss_G: 5.7539\n",
      "[1/25][50/782] Loss_D: 0.1569 Loss_G: 5.8900\n",
      "[1/25][51/782] Loss_D: 0.2517 Loss_G: 5.6101\n",
      "[1/25][52/782] Loss_D: 0.2169 Loss_G: 6.5490\n",
      "[1/25][53/782] Loss_D: 0.5643 Loss_G: 2.2126\n",
      "[1/25][54/782] Loss_D: 1.6448 Loss_G: 14.6997\n",
      "[1/25][55/782] Loss_D: 5.6290 Loss_G: 7.7239\n",
      "[1/25][56/782] Loss_D: 0.2397 Loss_G: 3.1269\n",
      "[1/25][57/782] Loss_D: 1.7118 Loss_G: 8.9273\n",
      "[1/25][58/782] Loss_D: 0.8355 Loss_G: 4.4641\n",
      "[1/25][59/782] Loss_D: 0.5607 Loss_G: 4.0896\n",
      "[1/25][60/782] Loss_D: 0.3308 Loss_G: 6.1087\n",
      "[1/25][61/782] Loss_D: 0.2359 Loss_G: 5.0847\n",
      "[1/25][62/782] Loss_D: 0.1869 Loss_G: 4.3789\n",
      "[1/25][63/782] Loss_D: 0.3269 Loss_G: 5.5165\n",
      "[1/25][64/782] Loss_D: 0.2991 Loss_G: 3.5868\n",
      "[1/25][65/782] Loss_D: 0.7194 Loss_G: 7.4745\n",
      "[1/25][66/782] Loss_D: 1.6349 Loss_G: 1.0323\n",
      "[1/25][67/782] Loss_D: 2.3866 Loss_G: 9.7179\n",
      "[1/25][68/782] Loss_D: 2.4868 Loss_G: 3.5096\n",
      "[1/25][69/782] Loss_D: 0.5773 Loss_G: 3.1592\n",
      "[1/25][70/782] Loss_D: 1.1125 Loss_G: 4.9371\n",
      "[1/25][71/782] Loss_D: 1.1082 Loss_G: 3.8910\n",
      "[1/25][72/782] Loss_D: 0.8563 Loss_G: 3.6873\n",
      "[1/25][73/782] Loss_D: 0.5475 Loss_G: 3.6732\n",
      "[1/25][74/782] Loss_D: 0.6317 Loss_G: 2.3263\n",
      "[1/25][75/782] Loss_D: 1.1692 Loss_G: 5.9438\n",
      "[1/25][76/782] Loss_D: 0.6224 Loss_G: 4.9424\n",
      "[1/25][77/782] Loss_D: 0.3126 Loss_G: 3.3261\n",
      "[1/25][78/782] Loss_D: 0.3050 Loss_G: 4.5955\n",
      "[1/25][79/782] Loss_D: 0.3278 Loss_G: 4.3144\n",
      "[1/25][80/782] Loss_D: 0.3351 Loss_G: 4.2310\n",
      "[1/25][81/782] Loss_D: 0.5528 Loss_G: 2.6996\n",
      "[1/25][82/782] Loss_D: 0.5938 Loss_G: 6.6840\n",
      "[1/25][83/782] Loss_D: 0.4238 Loss_G: 4.3974\n",
      "[1/25][84/782] Loss_D: 0.3905 Loss_G: 3.4631\n",
      "[1/25][85/782] Loss_D: 0.5747 Loss_G: 7.7653\n",
      "[1/25][86/782] Loss_D: 1.3183 Loss_G: 4.0421\n",
      "[1/25][87/782] Loss_D: 0.3234 Loss_G: 3.2497\n",
      "[1/25][88/782] Loss_D: 0.3836 Loss_G: 5.8027\n",
      "[1/25][89/782] Loss_D: 0.2228 Loss_G: 5.2785\n",
      "[1/25][90/782] Loss_D: 0.4668 Loss_G: 2.8810\n",
      "[1/25][91/782] Loss_D: 0.5714 Loss_G: 5.0503\n",
      "[1/25][92/782] Loss_D: 0.2426 Loss_G: 4.7599\n",
      "[1/25][93/782] Loss_D: 0.4310 Loss_G: 2.7868\n",
      "[1/25][94/782] Loss_D: 0.3987 Loss_G: 3.7444\n",
      "[1/25][95/782] Loss_D: 0.5765 Loss_G: 3.9460\n",
      "[1/25][96/782] Loss_D: 0.3994 Loss_G: 2.6715\n",
      "[1/25][97/782] Loss_D: 0.4923 Loss_G: 4.7279\n",
      "[1/25][98/782] Loss_D: 0.8520 Loss_G: 1.2037\n",
      "[1/25][99/782] Loss_D: 0.8266 Loss_G: 5.1408\n",
      "[1/25][100/782] Loss_D: 0.7929 Loss_G: 1.1229\n",
      "[1/25][101/782] Loss_D: 1.0569 Loss_G: 8.0896\n",
      "[1/25][102/782] Loss_D: 0.8753 Loss_G: 0.9872\n",
      "[1/25][103/782] Loss_D: 0.7571 Loss_G: 5.3019\n",
      "[1/25][104/782] Loss_D: 0.9733 Loss_G: 1.9309\n",
      "[1/25][105/782] Loss_D: 0.7321 Loss_G: 3.9637\n",
      "[1/25][106/782] Loss_D: 0.5073 Loss_G: 2.9116\n",
      "[1/25][107/782] Loss_D: 0.4246 Loss_G: 4.0337\n",
      "[1/25][108/782] Loss_D: 0.3308 Loss_G: 3.8980\n",
      "[1/25][109/782] Loss_D: 0.5134 Loss_G: 2.1894\n",
      "[1/25][110/782] Loss_D: 0.4849 Loss_G: 4.3475\n",
      "[1/25][111/782] Loss_D: 0.2241 Loss_G: 4.0868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/25][112/782] Loss_D: 0.4725 Loss_G: 1.6042\n",
      "[1/25][113/782] Loss_D: 0.5027 Loss_G: 5.0587\n",
      "[1/25][114/782] Loss_D: 0.4221 Loss_G: 3.8892\n",
      "[1/25][115/782] Loss_D: 0.3547 Loss_G: 2.4319\n",
      "[1/25][116/782] Loss_D: 0.3932 Loss_G: 4.4757\n",
      "[1/25][117/782] Loss_D: 0.1972 Loss_G: 4.7642\n",
      "[1/25][118/782] Loss_D: 0.2994 Loss_G: 3.5210\n",
      "[1/25][119/782] Loss_D: 0.3514 Loss_G: 4.4371\n",
      "[1/25][120/782] Loss_D: 0.2541 Loss_G: 3.6839\n",
      "[1/25][121/782] Loss_D: 0.2312 Loss_G: 2.8997\n",
      "[1/25][122/782] Loss_D: 0.3609 Loss_G: 5.5236\n",
      "[1/25][123/782] Loss_D: 0.1259 Loss_G: 5.3043\n",
      "[1/25][124/782] Loss_D: 0.2787 Loss_G: 3.6419\n",
      "[1/25][125/782] Loss_D: 0.2419 Loss_G: 3.9493\n",
      "[1/25][126/782] Loss_D: 0.1953 Loss_G: 4.3986\n",
      "[1/25][127/782] Loss_D: 0.0920 Loss_G: 4.6672\n",
      "[1/25][128/782] Loss_D: 0.1472 Loss_G: 4.2921\n",
      "[1/25][129/782] Loss_D: 0.1785 Loss_G: 4.2899\n",
      "[1/25][130/782] Loss_D: 0.2445 Loss_G: 3.5693\n",
      "[1/25][131/782] Loss_D: 0.1849 Loss_G: 4.5620\n",
      "[1/25][132/782] Loss_D: 0.2231 Loss_G: 5.7351\n",
      "[1/25][133/782] Loss_D: 0.8497 Loss_G: 0.5247\n",
      "[1/25][134/782] Loss_D: 2.2443 Loss_G: 10.2371\n",
      "[1/25][135/782] Loss_D: 2.1202 Loss_G: 0.1671\n",
      "[1/25][136/782] Loss_D: 2.9780 Loss_G: 10.2015\n",
      "[1/25][137/782] Loss_D: 2.0162 Loss_G: 5.4207\n",
      "[1/25][138/782] Loss_D: 0.7884 Loss_G: 1.1555\n",
      "[1/25][139/782] Loss_D: 2.3942 Loss_G: 5.5101\n",
      "[1/25][140/782] Loss_D: 0.6300 Loss_G: 5.6973\n",
      "[1/25][141/782] Loss_D: 0.8823 Loss_G: 2.7763\n",
      "[1/25][142/782] Loss_D: 1.9795 Loss_G: 4.4014\n",
      "[1/25][143/782] Loss_D: 1.2856 Loss_G: 3.3156\n",
      "[1/25][144/782] Loss_D: 1.7926 Loss_G: 4.9930\n",
      "[1/25][145/782] Loss_D: 2.0081 Loss_G: 1.7482\n",
      "[1/25][146/782] Loss_D: 2.2836 Loss_G: 7.1705\n",
      "[1/25][147/782] Loss_D: 1.6156 Loss_G: 4.7031\n",
      "[1/25][148/782] Loss_D: 0.4300 Loss_G: 3.1258\n",
      "[1/25][149/782] Loss_D: 0.9852 Loss_G: 4.5556\n",
      "[1/25][150/782] Loss_D: 0.7252 Loss_G: 3.4179\n",
      "[1/25][151/782] Loss_D: 0.9649 Loss_G: 2.2643\n",
      "[1/25][152/782] Loss_D: 0.8755 Loss_G: 2.6348\n",
      "[1/25][153/782] Loss_D: 0.9681 Loss_G: 3.2369\n",
      "[1/25][154/782] Loss_D: 0.7513 Loss_G: 2.5937\n",
      "[1/25][155/782] Loss_D: 0.6339 Loss_G: 2.7404\n",
      "[1/25][156/782] Loss_D: 0.3999 Loss_G: 3.7176\n",
      "[1/25][157/782] Loss_D: 0.2804 Loss_G: 4.0765\n",
      "[1/25][158/782] Loss_D: 0.2396 Loss_G: 3.4214\n",
      "[1/25][159/782] Loss_D: 0.4832 Loss_G: 3.0723\n",
      "[1/25][160/782] Loss_D: 0.7946 Loss_G: 4.8318\n",
      "[1/25][161/782] Loss_D: 0.4762 Loss_G: 3.8738\n",
      "[1/25][162/782] Loss_D: 0.5057 Loss_G: 2.0073\n",
      "[1/25][163/782] Loss_D: 0.4926 Loss_G: 4.3499\n",
      "[1/25][164/782] Loss_D: 0.4642 Loss_G: 4.1158\n",
      "[1/25][165/782] Loss_D: 0.8048 Loss_G: 2.5892\n",
      "[1/25][166/782] Loss_D: 0.6758 Loss_G: 3.5484\n",
      "[1/25][167/782] Loss_D: 0.5525 Loss_G: 3.6025\n",
      "[1/25][168/782] Loss_D: 0.4383 Loss_G: 3.2885\n",
      "[1/25][169/782] Loss_D: 0.3644 Loss_G: 3.3852\n",
      "[1/25][170/782] Loss_D: 0.3189 Loss_G: 3.1159\n",
      "[1/25][171/782] Loss_D: 0.4515 Loss_G: 3.3130\n",
      "[1/25][172/782] Loss_D: 0.3329 Loss_G: 4.2443\n",
      "[1/25][173/782] Loss_D: 0.3013 Loss_G: 3.7486\n",
      "[1/25][174/782] Loss_D: 0.6171 Loss_G: 2.3285\n",
      "[1/25][175/782] Loss_D: 0.6085 Loss_G: 5.1801\n",
      "[1/25][176/782] Loss_D: 0.3783 Loss_G: 3.8663\n",
      "[1/25][177/782] Loss_D: 0.2136 Loss_G: 3.7469\n",
      "[1/25][178/782] Loss_D: 0.2524 Loss_G: 3.6158\n",
      "[1/25][179/782] Loss_D: 0.3204 Loss_G: 4.5610\n",
      "[1/25][180/782] Loss_D: 0.2867 Loss_G: 3.8478\n",
      "[1/25][181/782] Loss_D: 0.2738 Loss_G: 3.2771\n",
      "[1/25][182/782] Loss_D: 0.6742 Loss_G: 6.4048\n",
      "[1/25][183/782] Loss_D: 0.4863 Loss_G: 4.7161\n",
      "[1/25][184/782] Loss_D: 0.5206 Loss_G: 3.4710\n",
      "[1/25][185/782] Loss_D: 0.7427 Loss_G: 4.1292\n",
      "[1/25][186/782] Loss_D: 0.2538 Loss_G: 4.7794\n",
      "[1/25][187/782] Loss_D: 0.3905 Loss_G: 4.2549\n",
      "[1/25][188/782] Loss_D: 0.3120 Loss_G: 5.7241\n",
      "[1/25][189/782] Loss_D: 0.2621 Loss_G: 3.9055\n",
      "[1/25][190/782] Loss_D: 0.4767 Loss_G: 3.6837\n",
      "[1/25][191/782] Loss_D: 0.5637 Loss_G: 4.3350\n",
      "[1/25][192/782] Loss_D: 0.4411 Loss_G: 4.4022\n",
      "[1/25][193/782] Loss_D: 0.3314 Loss_G: 3.7272\n",
      "[1/25][194/782] Loss_D: 0.4196 Loss_G: 6.5393\n",
      "[1/25][195/782] Loss_D: 0.1699 Loss_G: 6.4771\n",
      "[1/25][196/782] Loss_D: 0.2719 Loss_G: 4.0010\n",
      "[1/25][197/782] Loss_D: 0.1700 Loss_G: 3.3567\n",
      "[1/25][198/782] Loss_D: 0.4444 Loss_G: 6.9516\n",
      "[1/25][199/782] Loss_D: 0.1714 Loss_G: 5.4144\n",
      "[1/25][200/782] Loss_D: 0.3968 Loss_G: 2.9264\n",
      "[1/25][201/782] Loss_D: 0.5978 Loss_G: 6.3083\n",
      "[1/25][202/782] Loss_D: 0.4192 Loss_G: 4.6815\n",
      "[1/25][203/782] Loss_D: 0.9315 Loss_G: 3.3298\n",
      "[1/25][204/782] Loss_D: 0.7819 Loss_G: 7.2696\n",
      "[1/25][205/782] Loss_D: 0.6802 Loss_G: 4.3790\n",
      "[1/25][206/782] Loss_D: 0.9597 Loss_G: 6.2667\n",
      "[1/25][207/782] Loss_D: 0.4895 Loss_G: 4.2535\n",
      "[1/25][208/782] Loss_D: 0.8358 Loss_G: 3.7827\n",
      "[1/25][209/782] Loss_D: 0.5165 Loss_G: 5.6470\n",
      "[1/25][210/782] Loss_D: 0.4983 Loss_G: 3.9405\n",
      "[1/25][211/782] Loss_D: 0.5808 Loss_G: 3.9330\n",
      "[1/25][212/782] Loss_D: 0.8443 Loss_G: 8.4509\n",
      "[1/25][213/782] Loss_D: 0.7133 Loss_G: 6.3778\n",
      "[1/25][214/782] Loss_D: 0.1863 Loss_G: 3.2451\n",
      "[1/25][215/782] Loss_D: 0.8082 Loss_G: 8.0712\n",
      "[1/25][216/782] Loss_D: 0.5572 Loss_G: 6.1517\n",
      "[1/25][217/782] Loss_D: 0.0980 Loss_G: 3.4704\n",
      "[1/25][218/782] Loss_D: 0.5224 Loss_G: 5.7253\n",
      "[1/25][219/782] Loss_D: 0.6095 Loss_G: 2.8940\n",
      "[1/25][220/782] Loss_D: 0.8561 Loss_G: 6.4047\n",
      "[1/25][221/782] Loss_D: 1.9959 Loss_G: 1.4080\n",
      "[1/25][222/782] Loss_D: 1.3555 Loss_G: 7.6910\n",
      "[1/25][223/782] Loss_D: 1.5297 Loss_G: 2.6505\n",
      "[1/25][224/782] Loss_D: 1.1578 Loss_G: 3.6366\n",
      "[1/25][225/782] Loss_D: 0.3851 Loss_G: 5.0543\n",
      "[1/25][226/782] Loss_D: 1.3312 Loss_G: 0.7394\n",
      "[1/25][227/782] Loss_D: 1.5920 Loss_G: 5.6005\n",
      "[1/25][228/782] Loss_D: 0.8037 Loss_G: 3.4998\n",
      "[1/25][229/782] Loss_D: 0.5934 Loss_G: 1.9825\n",
      "[1/25][230/782] Loss_D: 0.5104 Loss_G: 3.9495\n",
      "[1/25][231/782] Loss_D: 0.4081 Loss_G: 3.7644\n",
      "[1/25][232/782] Loss_D: 0.3938 Loss_G: 2.6758\n",
      "[1/25][233/782] Loss_D: 0.5610 Loss_G: 3.4225\n",
      "[1/25][234/782] Loss_D: 0.5898 Loss_G: 2.8567\n",
      "[1/25][235/782] Loss_D: 0.6664 Loss_G: 3.3179\n",
      "[1/25][236/782] Loss_D: 0.3441 Loss_G: 3.1190\n",
      "[1/25][237/782] Loss_D: 0.2175 Loss_G: 3.1931\n",
      "[1/25][238/782] Loss_D: 0.5907 Loss_G: 3.7589\n",
      "[1/25][239/782] Loss_D: 0.5827 Loss_G: 2.5314\n",
      "[1/25][240/782] Loss_D: 0.4311 Loss_G: 4.0781\n",
      "[1/25][241/782] Loss_D: 0.3062 Loss_G: 3.9870\n",
      "[1/25][242/782] Loss_D: 0.5344 Loss_G: 1.7066\n",
      "[1/25][243/782] Loss_D: 0.7848 Loss_G: 6.0649\n",
      "[1/25][244/782] Loss_D: 0.5899 Loss_G: 3.6853\n",
      "[1/25][245/782] Loss_D: 0.2877 Loss_G: 3.8339\n",
      "[1/25][246/782] Loss_D: 0.2598 Loss_G: 4.0406\n",
      "[1/25][247/782] Loss_D: 0.3363 Loss_G: 3.8221\n",
      "[1/25][248/782] Loss_D: 0.4087 Loss_G: 2.6503\n",
      "[1/25][249/782] Loss_D: 0.4798 Loss_G: 4.7330\n",
      "[1/25][250/782] Loss_D: 0.4461 Loss_G: 3.2803\n",
      "[1/25][251/782] Loss_D: 0.3828 Loss_G: 4.5860\n",
      "[1/25][252/782] Loss_D: 0.3579 Loss_G: 4.2746\n",
      "[1/25][253/782] Loss_D: 0.3485 Loss_G: 3.0364\n",
      "[1/25][254/782] Loss_D: 0.7643 Loss_G: 6.7597\n",
      "[1/25][255/782] Loss_D: 1.1068 Loss_G: 3.6020\n",
      "[1/25][256/782] Loss_D: 0.7222 Loss_G: 6.6558\n",
      "[1/25][257/782] Loss_D: 0.4562 Loss_G: 4.4199\n",
      "[1/25][258/782] Loss_D: 0.1319 Loss_G: 4.2983\n",
      "[1/25][259/782] Loss_D: 0.4623 Loss_G: 6.4404\n",
      "[1/25][260/782] Loss_D: 0.8572 Loss_G: 2.7169\n",
      "[1/25][261/782] Loss_D: 0.7937 Loss_G: 6.2047\n",
      "[1/25][262/782] Loss_D: 0.7714 Loss_G: 2.9747\n",
      "[1/25][263/782] Loss_D: 0.5835 Loss_G: 4.4160\n",
      "[1/25][264/782] Loss_D: 0.5300 Loss_G: 2.4844\n",
      "[1/25][265/782] Loss_D: 0.5042 Loss_G: 4.3039\n",
      "[1/25][266/782] Loss_D: 0.5943 Loss_G: 2.0881\n",
      "[1/25][267/782] Loss_D: 0.6171 Loss_G: 5.3516\n",
      "[1/25][268/782] Loss_D: 0.6275 Loss_G: 2.7600\n",
      "[1/25][269/782] Loss_D: 0.5907 Loss_G: 4.5594\n",
      "[1/25][270/782] Loss_D: 0.6283 Loss_G: 1.9110\n",
      "[1/25][271/782] Loss_D: 1.2987 Loss_G: 6.9156\n",
      "[1/25][272/782] Loss_D: 1.4151 Loss_G: 2.3451\n",
      "[1/25][273/782] Loss_D: 0.6125 Loss_G: 3.5278\n",
      "[1/25][274/782] Loss_D: 0.5151 Loss_G: 2.8520\n",
      "[1/25][275/782] Loss_D: 0.5627 Loss_G: 4.9981\n",
      "[1/25][276/782] Loss_D: 0.7025 Loss_G: 2.8576\n",
      "[1/25][277/782] Loss_D: 0.4386 Loss_G: 3.9793\n",
      "[1/25][278/782] Loss_D: 0.3960 Loss_G: 4.1163\n",
      "[1/25][279/782] Loss_D: 0.3358 Loss_G: 3.4510\n",
      "[1/25][280/782] Loss_D: 0.3603 Loss_G: 4.4328\n",
      "[1/25][281/782] Loss_D: 0.4770 Loss_G: 3.0912\n",
      "[1/25][282/782] Loss_D: 0.5562 Loss_G: 4.8287\n",
      "[1/25][283/782] Loss_D: 0.4312 Loss_G: 3.4617\n",
      "[1/25][284/782] Loss_D: 0.8086 Loss_G: 2.5727\n",
      "[1/25][285/782] Loss_D: 0.7877 Loss_G: 6.4241\n",
      "[1/25][286/782] Loss_D: 0.9095 Loss_G: 3.2074\n",
      "[1/25][287/782] Loss_D: 0.3603 Loss_G: 3.9253\n",
      "[1/25][288/782] Loss_D: 0.3485 Loss_G: 4.9958\n",
      "[1/25][289/782] Loss_D: 0.5591 Loss_G: 2.3370\n",
      "[1/25][290/782] Loss_D: 0.4338 Loss_G: 4.7795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/25][291/782] Loss_D: 0.3876 Loss_G: 4.6757\n",
      "[1/25][292/782] Loss_D: 0.3611 Loss_G: 3.1853\n",
      "[1/25][293/782] Loss_D: 0.5956 Loss_G: 5.5594\n",
      "[1/25][294/782] Loss_D: 0.6415 Loss_G: 2.4907\n",
      "[1/25][295/782] Loss_D: 0.8133 Loss_G: 7.1940\n",
      "[1/25][296/782] Loss_D: 0.6737 Loss_G: 3.8503\n",
      "[1/25][297/782] Loss_D: 0.3835 Loss_G: 2.3782\n",
      "[1/25][298/782] Loss_D: 0.9520 Loss_G: 8.0191\n",
      "[1/25][299/782] Loss_D: 0.6737 Loss_G: 4.9072\n",
      "[1/25][300/782] Loss_D: 0.3420 Loss_G: 2.3250\n",
      "[1/25][301/782] Loss_D: 0.9278 Loss_G: 7.5533\n",
      "[1/25][302/782] Loss_D: 0.5647 Loss_G: 4.7813\n",
      "[1/25][303/782] Loss_D: 0.6588 Loss_G: 3.2321\n",
      "[1/25][304/782] Loss_D: 1.0027 Loss_G: 6.0408\n",
      "[1/25][305/782] Loss_D: 0.9430 Loss_G: 3.1479\n",
      "[1/25][306/782] Loss_D: 0.7131 Loss_G: 4.1451\n",
      "[1/25][307/782] Loss_D: 0.3220 Loss_G: 4.6047\n",
      "[1/25][308/782] Loss_D: 0.3009 Loss_G: 3.6634\n",
      "[1/25][309/782] Loss_D: 0.7005 Loss_G: 4.7286\n",
      "[1/25][310/782] Loss_D: 0.4040 Loss_G: 3.7870\n",
      "[1/25][311/782] Loss_D: 0.6336 Loss_G: 3.7419\n",
      "[1/25][312/782] Loss_D: 0.8665 Loss_G: 4.1449\n",
      "[1/25][313/782] Loss_D: 0.7713 Loss_G: 2.3051\n",
      "[1/25][314/782] Loss_D: 1.5006 Loss_G: 7.4131\n",
      "[1/25][315/782] Loss_D: 1.4570 Loss_G: 3.8013\n",
      "[1/25][316/782] Loss_D: 0.3025 Loss_G: 2.6381\n",
      "[1/25][317/782] Loss_D: 0.7275 Loss_G: 5.6298\n",
      "[1/25][318/782] Loss_D: 0.4634 Loss_G: 4.0707\n",
      "[1/25][319/782] Loss_D: 0.3792 Loss_G: 2.9758\n",
      "[1/25][320/782] Loss_D: 0.4887 Loss_G: 4.1772\n",
      "[1/25][321/782] Loss_D: 0.8719 Loss_G: 4.1994\n",
      "[1/25][322/782] Loss_D: 0.6415 Loss_G: 2.3208\n",
      "[1/25][323/782] Loss_D: 1.1777 Loss_G: 6.7973\n",
      "[1/25][324/782] Loss_D: 1.6081 Loss_G: 2.1281\n",
      "[1/25][325/782] Loss_D: 0.9623 Loss_G: 6.0123\n",
      "[1/25][326/782] Loss_D: 0.4451 Loss_G: 4.2982\n",
      "[1/25][327/782] Loss_D: 0.2887 Loss_G: 3.0031\n",
      "[1/25][328/782] Loss_D: 0.3627 Loss_G: 4.3722\n",
      "[1/25][329/782] Loss_D: 0.3236 Loss_G: 3.8680\n",
      "[1/25][330/782] Loss_D: 0.4274 Loss_G: 2.0943\n",
      "[1/25][331/782] Loss_D: 0.7640 Loss_G: 5.6366\n",
      "[1/25][332/782] Loss_D: 0.9390 Loss_G: 2.0732\n",
      "[1/25][333/782] Loss_D: 0.4439 Loss_G: 3.8767\n",
      "[1/25][334/782] Loss_D: 0.3529 Loss_G: 3.7196\n",
      "[1/25][335/782] Loss_D: 0.5476 Loss_G: 2.5630\n",
      "[1/25][336/782] Loss_D: 0.7333 Loss_G: 3.6934\n",
      "[1/25][337/782] Loss_D: 0.4221 Loss_G: 3.9713\n",
      "[1/25][338/782] Loss_D: 0.8764 Loss_G: 1.8829\n",
      "[1/25][339/782] Loss_D: 0.6991 Loss_G: 5.2169\n",
      "[1/25][340/782] Loss_D: 0.6434 Loss_G: 3.1282\n",
      "[1/25][341/782] Loss_D: 0.2814 Loss_G: 3.2295\n",
      "[1/25][342/782] Loss_D: 0.1913 Loss_G: 4.2163\n",
      "[1/25][343/782] Loss_D: 0.1777 Loss_G: 4.2338\n",
      "[1/25][344/782] Loss_D: 0.3118 Loss_G: 3.7727\n",
      "[1/25][345/782] Loss_D: 0.2620 Loss_G: 3.3560\n",
      "[1/25][346/782] Loss_D: 0.2406 Loss_G: 3.9044\n",
      "[1/25][347/782] Loss_D: 0.2798 Loss_G: 3.9163\n",
      "[1/25][348/782] Loss_D: 0.3942 Loss_G: 3.5894\n",
      "[1/25][349/782] Loss_D: 0.3747 Loss_G: 3.6786\n",
      "[1/25][350/782] Loss_D: 0.4197 Loss_G: 4.3275\n",
      "[1/25][351/782] Loss_D: 0.4231 Loss_G: 2.9932\n",
      "[1/25][352/782] Loss_D: 0.4949 Loss_G: 5.3843\n",
      "[1/25][353/782] Loss_D: 0.4762 Loss_G: 3.3876\n",
      "[1/25][354/782] Loss_D: 0.3916 Loss_G: 4.5936\n",
      "[1/25][355/782] Loss_D: 0.3725 Loss_G: 3.2827\n",
      "[1/25][356/782] Loss_D: 0.4853 Loss_G: 4.4222\n",
      "[1/25][357/782] Loss_D: 0.4597 Loss_G: 3.9896\n",
      "[1/25][358/782] Loss_D: 0.4563 Loss_G: 2.0576\n",
      "[1/25][359/782] Loss_D: 0.6032 Loss_G: 5.7779\n",
      "[1/25][360/782] Loss_D: 0.6356 Loss_G: 2.8024\n",
      "[1/25][361/782] Loss_D: 0.2637 Loss_G: 3.5152\n",
      "[1/25][362/782] Loss_D: 0.3087 Loss_G: 4.3851\n",
      "[1/25][363/782] Loss_D: 0.2146 Loss_G: 4.5892\n",
      "[1/25][364/782] Loss_D: 0.2800 Loss_G: 3.4330\n",
      "[1/25][365/782] Loss_D: 0.2628 Loss_G: 4.6389\n",
      "[1/25][366/782] Loss_D: 0.3333 Loss_G: 3.6371\n",
      "[1/25][367/782] Loss_D: 0.3831 Loss_G: 4.7429\n",
      "[1/25][368/782] Loss_D: 0.5690 Loss_G: 2.4491\n",
      "[1/25][369/782] Loss_D: 0.4085 Loss_G: 4.5042\n",
      "[1/25][370/782] Loss_D: 0.4662 Loss_G: 2.7144\n",
      "[1/25][371/782] Loss_D: 0.7228 Loss_G: 6.5941\n",
      "[1/25][372/782] Loss_D: 0.3627 Loss_G: 5.7446\n",
      "[1/25][373/782] Loss_D: 0.1397 Loss_G: 4.2438\n",
      "[1/25][374/782] Loss_D: 0.3711 Loss_G: 2.5033\n",
      "[1/25][375/782] Loss_D: 0.7431 Loss_G: 5.6439\n",
      "[1/25][376/782] Loss_D: 0.7028 Loss_G: 1.8104\n",
      "[1/25][377/782] Loss_D: 0.9011 Loss_G: 4.6925\n",
      "[1/25][378/782] Loss_D: 0.3854 Loss_G: 3.9891\n",
      "[1/25][379/782] Loss_D: 0.6990 Loss_G: 1.5684\n",
      "[1/25][380/782] Loss_D: 1.2073 Loss_G: 8.2388\n",
      "[1/25][381/782] Loss_D: 2.3490 Loss_G: 1.0401\n",
      "[1/25][382/782] Loss_D: 1.3675 Loss_G: 6.5610\n",
      "[1/25][383/782] Loss_D: 1.0600 Loss_G: 3.5042\n",
      "[1/25][384/782] Loss_D: 0.6092 Loss_G: 4.0727\n",
      "[1/25][385/782] Loss_D: 0.4013 Loss_G: 3.8609\n",
      "[1/25][386/782] Loss_D: 0.3183 Loss_G: 3.5126\n",
      "[1/25][387/782] Loss_D: 0.6117 Loss_G: 4.9151\n",
      "[1/25][388/782] Loss_D: 0.6609 Loss_G: 2.7215\n",
      "[1/25][389/782] Loss_D: 0.9698 Loss_G: 4.8386\n",
      "[1/25][390/782] Loss_D: 0.8403 Loss_G: 2.7826\n",
      "[1/25][391/782] Loss_D: 0.7199 Loss_G: 4.6733\n",
      "[1/25][392/782] Loss_D: 0.3870 Loss_G: 4.2900\n",
      "[1/25][393/782] Loss_D: 0.3383 Loss_G: 3.0386\n",
      "[1/25][394/782] Loss_D: 0.4604 Loss_G: 4.2120\n",
      "[1/25][395/782] Loss_D: 0.4345 Loss_G: 5.0001\n",
      "[1/25][396/782] Loss_D: 0.2733 Loss_G: 4.2948\n",
      "[1/25][397/782] Loss_D: 0.5451 Loss_G: 3.0909\n",
      "[1/25][398/782] Loss_D: 0.5604 Loss_G: 4.3623\n",
      "[1/25][399/782] Loss_D: 0.3910 Loss_G: 3.7450\n",
      "[1/25][400/782] Loss_D: 0.4656 Loss_G: 3.1946\n",
      "[1/25][401/782] Loss_D: 0.4704 Loss_G: 4.0286\n",
      "[1/25][402/782] Loss_D: 0.4411 Loss_G: 3.1239\n",
      "[1/25][403/782] Loss_D: 0.4288 Loss_G: 4.7586\n",
      "[1/25][404/782] Loss_D: 0.2768 Loss_G: 4.3542\n",
      "[1/25][405/782] Loss_D: 0.3466 Loss_G: 3.1627\n",
      "[1/25][406/782] Loss_D: 0.2980 Loss_G: 4.0468\n",
      "[1/25][407/782] Loss_D: 0.2788 Loss_G: 4.4666\n",
      "[1/25][408/782] Loss_D: 0.3345 Loss_G: 3.2804\n",
      "[1/25][409/782] Loss_D: 0.4220 Loss_G: 4.7712\n",
      "[1/25][410/782] Loss_D: 0.2308 Loss_G: 4.1087\n",
      "[1/25][411/782] Loss_D: 0.3792 Loss_G: 2.3593\n",
      "[1/25][412/782] Loss_D: 0.5244 Loss_G: 5.0378\n",
      "[1/25][413/782] Loss_D: 0.3362 Loss_G: 3.6848\n",
      "[1/25][414/782] Loss_D: 0.2995 Loss_G: 3.7349\n",
      "[1/25][415/782] Loss_D: 0.3083 Loss_G: 4.0258\n",
      "[1/25][416/782] Loss_D: 0.5081 Loss_G: 2.3794\n",
      "[1/25][417/782] Loss_D: 0.9787 Loss_G: 7.6100\n",
      "[1/25][418/782] Loss_D: 1.0839 Loss_G: 2.4235\n",
      "[1/25][419/782] Loss_D: 0.5902 Loss_G: 6.9337\n",
      "[1/25][420/782] Loss_D: 0.3230 Loss_G: 5.0489\n",
      "[1/25][421/782] Loss_D: 0.2643 Loss_G: 3.3712\n",
      "[1/25][422/782] Loss_D: 0.3539 Loss_G: 4.9526\n",
      "[1/25][423/782] Loss_D: 0.4371 Loss_G: 3.0365\n",
      "[1/25][424/782] Loss_D: 0.2822 Loss_G: 3.2551\n",
      "[1/25][425/782] Loss_D: 0.4578 Loss_G: 5.2261\n",
      "[1/25][426/782] Loss_D: 0.7166 Loss_G: 2.2212\n",
      "[1/25][427/782] Loss_D: 0.6844 Loss_G: 4.4115\n",
      "[1/25][428/782] Loss_D: 0.5010 Loss_G: 3.0344\n",
      "[1/25][429/782] Loss_D: 0.5522 Loss_G: 4.4033\n",
      "[1/25][430/782] Loss_D: 0.3987 Loss_G: 3.3449\n",
      "[1/25][431/782] Loss_D: 0.5153 Loss_G: 3.9735\n",
      "[1/25][432/782] Loss_D: 0.2994 Loss_G: 3.7443\n",
      "[1/25][433/782] Loss_D: 0.3125 Loss_G: 3.0480\n",
      "[1/25][434/782] Loss_D: 0.2491 Loss_G: 4.1855\n",
      "[1/25][435/782] Loss_D: 0.3760 Loss_G: 4.4889\n",
      "[1/25][436/782] Loss_D: 0.5604 Loss_G: 2.3010\n",
      "[1/25][437/782] Loss_D: 0.6037 Loss_G: 6.1995\n",
      "[1/25][438/782] Loss_D: 0.2047 Loss_G: 5.8761\n",
      "[1/25][439/782] Loss_D: 0.4300 Loss_G: 2.3239\n",
      "[1/25][440/782] Loss_D: 0.7177 Loss_G: 6.0610\n",
      "[1/25][441/782] Loss_D: 0.7333 Loss_G: 2.5898\n",
      "[1/25][442/782] Loss_D: 0.8413 Loss_G: 6.4393\n",
      "[1/25][443/782] Loss_D: 0.8678 Loss_G: 2.2476\n",
      "[1/25][444/782] Loss_D: 0.3231 Loss_G: 4.4560\n",
      "[1/25][445/782] Loss_D: 0.3044 Loss_G: 5.7880\n",
      "[1/25][446/782] Loss_D: 0.4096 Loss_G: 3.2559\n",
      "[1/25][447/782] Loss_D: 0.4219 Loss_G: 4.8170\n",
      "[1/25][448/782] Loss_D: 0.3658 Loss_G: 4.9044\n",
      "[1/25][449/782] Loss_D: 0.3409 Loss_G: 3.3374\n",
      "[1/25][450/782] Loss_D: 0.4975 Loss_G: 4.7944\n",
      "[1/25][451/782] Loss_D: 0.3324 Loss_G: 4.9049\n",
      "[1/25][452/782] Loss_D: 0.6998 Loss_G: 2.8040\n",
      "[1/25][453/782] Loss_D: 0.8042 Loss_G: 7.1584\n",
      "[1/25][454/782] Loss_D: 0.8585 Loss_G: 2.3429\n",
      "[1/25][455/782] Loss_D: 0.6164 Loss_G: 5.3387\n",
      "[1/25][456/782] Loss_D: 0.3164 Loss_G: 4.1465\n",
      "[1/25][457/782] Loss_D: 0.3842 Loss_G: 4.2182\n",
      "[1/25][458/782] Loss_D: 0.3482 Loss_G: 4.4914\n",
      "[1/25][459/782] Loss_D: 0.3755 Loss_G: 4.5373\n",
      "[1/25][460/782] Loss_D: 0.3347 Loss_G: 5.1398\n",
      "[1/25][461/782] Loss_D: 0.4532 Loss_G: 2.5676\n",
      "[1/25][462/782] Loss_D: 0.5230 Loss_G: 5.7570\n",
      "[1/25][463/782] Loss_D: 0.7276 Loss_G: 2.0938\n",
      "[1/25][464/782] Loss_D: 0.6049 Loss_G: 5.7997\n",
      "[1/25][465/782] Loss_D: 0.4506 Loss_G: 3.4612\n",
      "[1/25][466/782] Loss_D: 0.6650 Loss_G: 5.7670\n",
      "[1/25][467/782] Loss_D: 0.3530 Loss_G: 3.9024\n",
      "[1/25][468/782] Loss_D: 0.7563 Loss_G: 1.9830\n",
      "[1/25][469/782] Loss_D: 1.7679 Loss_G: 9.4896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/25][470/782] Loss_D: 2.4539 Loss_G: 3.4163\n",
      "[1/25][471/782] Loss_D: 0.3968 Loss_G: 2.9679\n",
      "[1/25][472/782] Loss_D: 0.7761 Loss_G: 7.0695\n",
      "[1/25][473/782] Loss_D: 1.3592 Loss_G: 3.1276\n",
      "[1/25][474/782] Loss_D: 0.6089 Loss_G: 4.0121\n",
      "[1/25][475/782] Loss_D: 0.4738 Loss_G: 5.8071\n",
      "[1/25][476/782] Loss_D: 0.6377 Loss_G: 3.3640\n",
      "[1/25][477/782] Loss_D: 0.4830 Loss_G: 3.7554\n",
      "[1/25][478/782] Loss_D: 0.5063 Loss_G: 4.2813\n",
      "[1/25][479/782] Loss_D: 0.5390 Loss_G: 3.2729\n",
      "[1/25][480/782] Loss_D: 1.2212 Loss_G: 2.9807\n",
      "[1/25][481/782] Loss_D: 0.7948 Loss_G: 4.7227\n",
      "[1/25][482/782] Loss_D: 1.3820 Loss_G: 2.0950\n",
      "[1/25][483/782] Loss_D: 0.9586 Loss_G: 6.3572\n",
      "[1/25][484/782] Loss_D: 0.4972 Loss_G: 4.3321\n",
      "[1/25][485/782] Loss_D: 0.4646 Loss_G: 2.9343\n",
      "[1/25][486/782] Loss_D: 0.4710 Loss_G: 4.5146\n",
      "[1/25][487/782] Loss_D: 0.7697 Loss_G: 4.5574\n",
      "[1/25][488/782] Loss_D: 0.3791 Loss_G: 3.3593\n",
      "[1/25][489/782] Loss_D: 0.6279 Loss_G: 4.5674\n",
      "[1/25][490/782] Loss_D: 0.2858 Loss_G: 4.2418\n",
      "[1/25][491/782] Loss_D: 0.3038 Loss_G: 3.4228\n",
      "[1/25][492/782] Loss_D: 0.3287 Loss_G: 3.2902\n",
      "[1/25][493/782] Loss_D: 0.3855 Loss_G: 5.2624\n",
      "[1/25][494/782] Loss_D: 0.3826 Loss_G: 3.3780\n",
      "[1/25][495/782] Loss_D: 0.3014 Loss_G: 3.8062\n",
      "[1/25][496/782] Loss_D: 0.4299 Loss_G: 4.7997\n",
      "[1/25][497/782] Loss_D: 0.6502 Loss_G: 1.9870\n",
      "[1/25][498/782] Loss_D: 1.0550 Loss_G: 6.7535\n",
      "[1/25][499/782] Loss_D: 0.8041 Loss_G: 3.0043\n",
      "[1/25][500/782] Loss_D: 0.7494 Loss_G: 5.9641\n",
      "[1/25][501/782] Loss_D: 0.7403 Loss_G: 2.6599\n",
      "[1/25][502/782] Loss_D: 0.4967 Loss_G: 4.2438\n",
      "[1/25][503/782] Loss_D: 0.4869 Loss_G: 3.7464\n",
      "[1/25][504/782] Loss_D: 0.4978 Loss_G: 3.6086\n",
      "[1/25][505/782] Loss_D: 0.3712 Loss_G: 4.3847\n",
      "[1/25][506/782] Loss_D: 0.4259 Loss_G: 3.2699\n",
      "[1/25][507/782] Loss_D: 0.3568 Loss_G: 4.1969\n",
      "[1/25][508/782] Loss_D: 0.3657 Loss_G: 2.9962\n",
      "[1/25][509/782] Loss_D: 0.5933 Loss_G: 6.1060\n",
      "[1/25][510/782] Loss_D: 1.4896 Loss_G: 0.8849\n",
      "[1/25][511/782] Loss_D: 1.4478 Loss_G: 7.8136\n",
      "[1/25][512/782] Loss_D: 1.3894 Loss_G: 3.6925\n",
      "[1/25][513/782] Loss_D: 0.4137 Loss_G: 2.2115\n",
      "[1/25][514/782] Loss_D: 0.7772 Loss_G: 6.1134\n",
      "[1/25][515/782] Loss_D: 0.6282 Loss_G: 4.2041\n",
      "[1/25][516/782] Loss_D: 1.0180 Loss_G: 2.6945\n",
      "[1/25][517/782] Loss_D: 1.2638 Loss_G: 6.0460\n",
      "[1/25][518/782] Loss_D: 0.7119 Loss_G: 4.1473\n",
      "[1/25][519/782] Loss_D: 0.3929 Loss_G: 3.1180\n",
      "[1/25][520/782] Loss_D: 1.0509 Loss_G: 6.7716\n",
      "[1/25][521/782] Loss_D: 0.7372 Loss_G: 3.6763\n",
      "[1/25][522/782] Loss_D: 0.7784 Loss_G: 3.5685\n",
      "[1/25][523/782] Loss_D: 0.8389 Loss_G: 2.9199\n",
      "[1/25][524/782] Loss_D: 0.8427 Loss_G: 4.4747\n",
      "[1/25][525/782] Loss_D: 0.7776 Loss_G: 2.3609\n",
      "[1/25][526/782] Loss_D: 0.6290 Loss_G: 5.7650\n",
      "[1/25][527/782] Loss_D: 0.7301 Loss_G: 2.3474\n",
      "[1/25][528/782] Loss_D: 0.4972 Loss_G: 4.5048\n",
      "[1/25][529/782] Loss_D: 0.3271 Loss_G: 4.4291\n",
      "[1/25][530/782] Loss_D: 0.2063 Loss_G: 3.8753\n",
      "[1/25][531/782] Loss_D: 0.4502 Loss_G: 3.5276\n",
      "[1/25][532/782] Loss_D: 0.2579 Loss_G: 3.5821\n",
      "[1/25][533/782] Loss_D: 0.5242 Loss_G: 5.5047\n",
      "[1/25][534/782] Loss_D: 0.9555 Loss_G: 1.8339\n",
      "[1/25][535/782] Loss_D: 1.1419 Loss_G: 7.1272\n",
      "[1/25][536/782] Loss_D: 1.0819 Loss_G: 3.2714\n",
      "[1/25][537/782] Loss_D: 0.4588 Loss_G: 3.6435\n",
      "[1/25][538/782] Loss_D: 0.4718 Loss_G: 5.3303\n",
      "[1/25][539/782] Loss_D: 0.5050 Loss_G: 3.3841\n",
      "[1/25][540/782] Loss_D: 0.4646 Loss_G: 4.1836\n",
      "[1/25][541/782] Loss_D: 0.2179 Loss_G: 4.2021\n",
      "[1/25][542/782] Loss_D: 0.4067 Loss_G: 3.5760\n",
      "[1/25][543/782] Loss_D: 0.1741 Loss_G: 4.4037\n",
      "[1/25][544/782] Loss_D: 0.2207 Loss_G: 4.3364\n",
      "[1/25][545/782] Loss_D: 0.3579 Loss_G: 3.4098\n",
      "[1/25][546/782] Loss_D: 0.3749 Loss_G: 4.6305\n",
      "[1/25][547/782] Loss_D: 0.4511 Loss_G: 3.3073\n",
      "[1/25][548/782] Loss_D: 0.6290 Loss_G: 2.9095\n",
      "[1/25][549/782] Loss_D: 0.7226 Loss_G: 6.3553\n",
      "[1/25][550/782] Loss_D: 1.1970 Loss_G: 1.6453\n",
      "[1/25][551/782] Loss_D: 1.2849 Loss_G: 6.5804\n",
      "[1/25][552/782] Loss_D: 1.9004 Loss_G: 0.4158\n",
      "[1/25][553/782] Loss_D: 2.2909 Loss_G: 9.4040\n",
      "[1/25][554/782] Loss_D: 1.6887 Loss_G: 5.0581\n",
      "[1/25][555/782] Loss_D: 0.5355 Loss_G: 1.4972\n",
      "[1/25][556/782] Loss_D: 1.5095 Loss_G: 6.0680\n",
      "[1/25][557/782] Loss_D: 0.5667 Loss_G: 4.8902\n",
      "[1/25][558/782] Loss_D: 1.0127 Loss_G: 1.1029\n",
      "[1/25][559/782] Loss_D: 2.0588 Loss_G: 6.2750\n",
      "[1/25][560/782] Loss_D: 0.9246 Loss_G: 3.2601\n",
      "[1/25][561/782] Loss_D: 0.6787 Loss_G: 3.0314\n",
      "[1/25][562/782] Loss_D: 0.5848 Loss_G: 4.1190\n",
      "[1/25][563/782] Loss_D: 0.7439 Loss_G: 3.3044\n",
      "[1/25][564/782] Loss_D: 0.4376 Loss_G: 3.4065\n",
      "[1/25][565/782] Loss_D: 0.3452 Loss_G: 3.6495\n",
      "[1/25][566/782] Loss_D: 0.6090 Loss_G: 3.0933\n",
      "[1/25][567/782] Loss_D: 0.6193 Loss_G: 3.5993\n",
      "[1/25][568/782] Loss_D: 0.4955 Loss_G: 3.1943\n",
      "[1/25][569/782] Loss_D: 0.5585 Loss_G: 3.7839\n",
      "[1/25][570/782] Loss_D: 0.6169 Loss_G: 2.9449\n",
      "[1/25][571/782] Loss_D: 0.7360 Loss_G: 4.5516\n",
      "[1/25][572/782] Loss_D: 0.5828 Loss_G: 3.4671\n",
      "[1/25][573/782] Loss_D: 0.6092 Loss_G: 3.4977\n",
      "[1/25][574/782] Loss_D: 0.9716 Loss_G: 4.9894\n",
      "[1/25][575/782] Loss_D: 0.7996 Loss_G: 2.7032\n",
      "[1/25][576/782] Loss_D: 0.5749 Loss_G: 4.0934\n",
      "[1/25][577/782] Loss_D: 0.4625 Loss_G: 4.0056\n",
      "[1/25][578/782] Loss_D: 0.3417 Loss_G: 4.4161\n",
      "[1/25][579/782] Loss_D: 0.3567 Loss_G: 3.3732\n",
      "[1/25][580/782] Loss_D: 0.5365 Loss_G: 4.2423\n",
      "[1/25][581/782] Loss_D: 0.4749 Loss_G: 3.6100\n",
      "[1/25][582/782] Loss_D: 0.4548 Loss_G: 3.4940\n",
      "[1/25][583/782] Loss_D: 0.5304 Loss_G: 3.6946\n",
      "[1/25][584/782] Loss_D: 0.2792 Loss_G: 3.5948\n",
      "[1/25][585/782] Loss_D: 0.4623 Loss_G: 3.4452\n",
      "[1/25][586/782] Loss_D: 0.4514 Loss_G: 4.5025\n",
      "[1/25][587/782] Loss_D: 0.4033 Loss_G: 3.3041\n",
      "[1/25][588/782] Loss_D: 0.6214 Loss_G: 2.9330\n",
      "[1/25][589/782] Loss_D: 0.6927 Loss_G: 4.2461\n",
      "[1/25][590/782] Loss_D: 0.4885 Loss_G: 3.0523\n",
      "[1/25][591/782] Loss_D: 0.5146 Loss_G: 3.9621\n",
      "[1/25][592/782] Loss_D: 0.4195 Loss_G: 2.9000\n",
      "[1/25][593/782] Loss_D: 0.5164 Loss_G: 4.8234\n",
      "[1/25][594/782] Loss_D: 0.4887 Loss_G: 3.3501\n",
      "[1/25][595/782] Loss_D: 0.3274 Loss_G: 3.5238\n",
      "[1/25][596/782] Loss_D: 0.4587 Loss_G: 3.4077\n",
      "[1/25][597/782] Loss_D: 0.3293 Loss_G: 3.2893\n",
      "[1/25][598/782] Loss_D: 0.4475 Loss_G: 4.1289\n",
      "[1/25][599/782] Loss_D: 0.5379 Loss_G: 2.5947\n",
      "[1/25][600/782] Loss_D: 0.5004 Loss_G: 4.1560\n",
      "[1/25][601/782] Loss_D: 0.3280 Loss_G: 3.7406\n",
      "[1/25][602/782] Loss_D: 0.3410 Loss_G: 2.4727\n",
      "[1/25][603/782] Loss_D: 0.5284 Loss_G: 4.1804\n",
      "[1/25][604/782] Loss_D: 0.3451 Loss_G: 3.8190\n",
      "[1/25][605/782] Loss_D: 0.3861 Loss_G: 3.3259\n",
      "[1/25][606/782] Loss_D: 0.3368 Loss_G: 4.9095\n",
      "[1/25][607/782] Loss_D: 0.6284 Loss_G: 1.8020\n",
      "[1/25][608/782] Loss_D: 0.7032 Loss_G: 4.6792\n",
      "[1/25][609/782] Loss_D: 0.8697 Loss_G: 2.1211\n",
      "[1/25][610/782] Loss_D: 0.6599 Loss_G: 5.4252\n",
      "[1/25][611/782] Loss_D: 0.4973 Loss_G: 3.3152\n",
      "[1/25][612/782] Loss_D: 0.4882 Loss_G: 4.4837\n",
      "[1/25][613/782] Loss_D: 0.2665 Loss_G: 4.3678\n",
      "[1/25][614/782] Loss_D: 0.5509 Loss_G: 1.4904\n",
      "[1/25][615/782] Loss_D: 0.9783 Loss_G: 7.5578\n",
      "[1/25][616/782] Loss_D: 0.6837 Loss_G: 4.8111\n",
      "[1/25][617/782] Loss_D: 0.4145 Loss_G: 1.8441\n",
      "[1/25][618/782] Loss_D: 1.0294 Loss_G: 7.3954\n",
      "[1/25][619/782] Loss_D: 0.4001 Loss_G: 4.7581\n",
      "[1/25][620/782] Loss_D: 0.5541 Loss_G: 1.6194\n",
      "[1/25][621/782] Loss_D: 1.0251 Loss_G: 7.1275\n",
      "[1/25][622/782] Loss_D: 0.8938 Loss_G: 2.7736\n",
      "[1/25][623/782] Loss_D: 0.7131 Loss_G: 4.0772\n",
      "[1/25][624/782] Loss_D: 0.6084 Loss_G: 3.2553\n",
      "[1/25][625/782] Loss_D: 0.7710 Loss_G: 2.8743\n",
      "[1/25][626/782] Loss_D: 1.0857 Loss_G: 5.8132\n",
      "[1/25][627/782] Loss_D: 1.2093 Loss_G: 1.4255\n",
      "[1/25][628/782] Loss_D: 1.1969 Loss_G: 7.0188\n",
      "[1/25][629/782] Loss_D: 1.2821 Loss_G: 2.8844\n",
      "[1/25][630/782] Loss_D: 0.4738 Loss_G: 4.5866\n",
      "[1/25][631/782] Loss_D: 0.3585 Loss_G: 4.2014\n",
      "[1/25][632/782] Loss_D: 0.4797 Loss_G: 3.8380\n",
      "[1/25][633/782] Loss_D: 0.4037 Loss_G: 4.2084\n",
      "[1/25][634/782] Loss_D: 0.3910 Loss_G: 3.7272\n",
      "[1/25][635/782] Loss_D: 0.6730 Loss_G: 5.3704\n",
      "[1/25][636/782] Loss_D: 0.9535 Loss_G: 1.3970\n",
      "[1/25][637/782] Loss_D: 0.9115 Loss_G: 7.3349\n",
      "[1/25][638/782] Loss_D: 0.6220 Loss_G: 4.3140\n",
      "[1/25][639/782] Loss_D: 0.5721 Loss_G: 3.5363\n",
      "[1/25][640/782] Loss_D: 0.6279 Loss_G: 5.3365\n",
      "[1/25][641/782] Loss_D: 0.8296 Loss_G: 1.7084\n",
      "[1/25][642/782] Loss_D: 0.6017 Loss_G: 4.8691\n",
      "[1/25][643/782] Loss_D: 0.2363 Loss_G: 4.8347\n",
      "[1/25][644/782] Loss_D: 0.2172 Loss_G: 3.9304\n",
      "[1/25][645/782] Loss_D: 0.2419 Loss_G: 3.8604\n",
      "[1/25][646/782] Loss_D: 0.4657 Loss_G: 4.3086\n",
      "[1/25][647/782] Loss_D: 0.7313 Loss_G: 3.0787\n",
      "[1/25][648/782] Loss_D: 0.9890 Loss_G: 3.4846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/25][649/782] Loss_D: 0.5066 Loss_G: 3.0829\n",
      "[1/25][650/782] Loss_D: 0.3503 Loss_G: 4.0595\n",
      "[1/25][651/782] Loss_D: 0.3075 Loss_G: 3.7590\n",
      "[1/25][652/782] Loss_D: 0.2419 Loss_G: 3.7718\n",
      "[1/25][653/782] Loss_D: 0.2941 Loss_G: 3.6726\n",
      "[1/25][654/782] Loss_D: 0.2801 Loss_G: 3.8477\n",
      "[1/25][655/782] Loss_D: 0.5424 Loss_G: 4.3421\n",
      "[1/25][656/782] Loss_D: 0.6543 Loss_G: 1.9733\n",
      "[1/25][657/782] Loss_D: 0.9858 Loss_G: 7.1022\n",
      "[1/25][658/782] Loss_D: 1.3924 Loss_G: 2.5377\n",
      "[1/25][659/782] Loss_D: 0.4385 Loss_G: 3.1463\n",
      "[1/25][660/782] Loss_D: 0.2922 Loss_G: 4.8956\n",
      "[1/25][661/782] Loss_D: 0.6293 Loss_G: 2.4313\n",
      "[1/25][662/782] Loss_D: 0.3712 Loss_G: 4.2785\n",
      "[1/25][663/782] Loss_D: 0.3310 Loss_G: 4.5573\n",
      "[1/25][664/782] Loss_D: 0.2613 Loss_G: 3.5061\n",
      "[1/25][665/782] Loss_D: 0.3097 Loss_G: 3.4699\n",
      "[1/25][666/782] Loss_D: 0.4544 Loss_G: 3.3664\n",
      "[1/25][667/782] Loss_D: 0.5189 Loss_G: 3.0525\n",
      "[1/25][668/782] Loss_D: 0.3434 Loss_G: 5.1107\n",
      "[1/25][669/782] Loss_D: 0.4725 Loss_G: 2.8052\n",
      "[1/25][670/782] Loss_D: 0.4479 Loss_G: 3.7192\n",
      "[1/25][671/782] Loss_D: 0.5461 Loss_G: 3.0197\n",
      "[1/25][672/782] Loss_D: 0.5260 Loss_G: 5.5677\n",
      "[1/25][673/782] Loss_D: 0.8314 Loss_G: 2.2129\n",
      "[1/25][674/782] Loss_D: 0.6330 Loss_G: 5.3752\n",
      "[1/25][675/782] Loss_D: 0.3584 Loss_G: 4.0635\n",
      "[1/25][676/782] Loss_D: 0.2814 Loss_G: 3.6993\n",
      "[1/25][677/782] Loss_D: 0.3790 Loss_G: 3.6815\n",
      "[1/25][678/782] Loss_D: 0.3706 Loss_G: 4.1008\n",
      "[1/25][679/782] Loss_D: 0.2986 Loss_G: 3.7484\n",
      "[1/25][680/782] Loss_D: 0.5602 Loss_G: 4.2488\n",
      "[1/25][681/782] Loss_D: 0.5829 Loss_G: 3.5773\n",
      "[1/25][682/782] Loss_D: 0.4596 Loss_G: 4.5946\n",
      "[1/25][683/782] Loss_D: 0.2327 Loss_G: 4.0643\n",
      "[1/25][684/782] Loss_D: 0.2760 Loss_G: 4.3112\n",
      "[1/25][685/782] Loss_D: 0.2739 Loss_G: 4.0883\n",
      "[1/25][686/782] Loss_D: 0.3893 Loss_G: 2.7157\n",
      "[1/25][687/782] Loss_D: 0.7668 Loss_G: 7.0345\n",
      "[1/25][688/782] Loss_D: 0.6989 Loss_G: 4.2869\n",
      "[1/25][689/782] Loss_D: 0.2399 Loss_G: 2.9100\n",
      "[1/25][690/782] Loss_D: 0.4810 Loss_G: 5.3486\n",
      "[1/25][691/782] Loss_D: 0.3387 Loss_G: 4.1586\n",
      "[1/25][692/782] Loss_D: 0.5546 Loss_G: 2.4276\n",
      "[1/25][693/782] Loss_D: 0.6720 Loss_G: 5.5643\n",
      "[1/25][694/782] Loss_D: 0.7984 Loss_G: 2.5396\n",
      "[1/25][695/782] Loss_D: 0.5997 Loss_G: 5.8721\n",
      "[1/25][696/782] Loss_D: 0.8381 Loss_G: 2.5080\n",
      "[1/25][697/782] Loss_D: 0.6189 Loss_G: 6.4426\n",
      "[1/25][698/782] Loss_D: 0.3650 Loss_G: 4.2946\n",
      "[1/25][699/782] Loss_D: 0.6021 Loss_G: 4.5917\n",
      "[1/25][700/782] Loss_D: 0.3730 Loss_G: 3.7773\n",
      "[1/25][701/782] Loss_D: 0.5553 Loss_G: 3.4578\n",
      "[1/25][702/782] Loss_D: 0.3888 Loss_G: 4.2277\n",
      "[1/25][703/782] Loss_D: 0.3414 Loss_G: 4.6164\n",
      "[1/25][704/782] Loss_D: 0.6487 Loss_G: 1.7499\n",
      "[1/25][705/782] Loss_D: 1.6185 Loss_G: 7.5964\n",
      "[1/25][706/782] Loss_D: 1.3174 Loss_G: 2.4976\n",
      "[1/25][707/782] Loss_D: 0.6648 Loss_G: 4.5926\n",
      "[1/25][708/782] Loss_D: 0.3913 Loss_G: 4.2539\n",
      "[1/25][709/782] Loss_D: 0.7566 Loss_G: 3.1578\n",
      "[1/25][710/782] Loss_D: 0.9921 Loss_G: 5.4394\n",
      "[1/25][711/782] Loss_D: 0.7674 Loss_G: 2.4791\n",
      "[1/25][712/782] Loss_D: 1.1241 Loss_G: 5.7673\n",
      "[1/25][713/782] Loss_D: 1.1371 Loss_G: 1.8614\n",
      "[1/25][714/782] Loss_D: 0.9344 Loss_G: 6.3413\n",
      "[1/25][715/782] Loss_D: 0.5020 Loss_G: 3.8696\n",
      "[1/25][716/782] Loss_D: 0.4424 Loss_G: 2.9935\n",
      "[1/25][717/782] Loss_D: 0.9193 Loss_G: 7.5384\n",
      "[1/25][718/782] Loss_D: 1.6232 Loss_G: 3.3732\n",
      "[1/25][719/782] Loss_D: 0.4095 Loss_G: 2.7405\n",
      "[1/25][720/782] Loss_D: 0.5262 Loss_G: 4.5624\n",
      "[1/25][721/782] Loss_D: 0.2342 Loss_G: 4.5145\n",
      "[1/25][722/782] Loss_D: 0.2868 Loss_G: 3.5849\n",
      "[1/25][723/782] Loss_D: 0.6442 Loss_G: 2.4366\n",
      "[1/25][724/782] Loss_D: 0.6375 Loss_G: 5.6957\n",
      "[1/25][725/782] Loss_D: 0.6844 Loss_G: 3.3044\n",
      "[1/25][726/782] Loss_D: 0.3218 Loss_G: 3.0806\n",
      "[1/25][727/782] Loss_D: 0.2978 Loss_G: 3.9324\n",
      "[1/25][728/782] Loss_D: 0.2482 Loss_G: 4.2132\n",
      "[1/25][729/782] Loss_D: 0.4159 Loss_G: 3.2628\n",
      "[1/25][730/782] Loss_D: 0.3408 Loss_G: 3.3701\n",
      "[1/25][731/782] Loss_D: 0.3668 Loss_G: 3.1383\n",
      "[1/25][732/782] Loss_D: 0.2928 Loss_G: 3.7584\n",
      "[1/25][733/782] Loss_D: 0.3766 Loss_G: 3.0858\n",
      "[1/25][734/782] Loss_D: 0.4397 Loss_G: 5.1059\n",
      "[1/25][735/782] Loss_D: 0.7260 Loss_G: 1.5889\n",
      "[1/25][736/782] Loss_D: 1.0875 Loss_G: 6.3490\n",
      "[1/25][737/782] Loss_D: 0.9251 Loss_G: 2.2041\n",
      "[1/25][738/782] Loss_D: 0.7987 Loss_G: 4.6407\n",
      "[1/25][739/782] Loss_D: 0.3955 Loss_G: 3.5718\n",
      "[1/25][740/782] Loss_D: 0.4121 Loss_G: 2.6063\n",
      "[1/25][741/782] Loss_D: 0.7813 Loss_G: 6.5302\n",
      "[1/25][742/782] Loss_D: 0.8326 Loss_G: 3.8478\n",
      "[1/25][743/782] Loss_D: 0.6244 Loss_G: 2.8301\n",
      "[1/25][744/782] Loss_D: 0.8332 Loss_G: 4.2450\n",
      "[1/25][745/782] Loss_D: 0.5336 Loss_G: 3.0479\n",
      "[1/25][746/782] Loss_D: 0.6178 Loss_G: 3.6482\n",
      "[1/25][747/782] Loss_D: 0.3781 Loss_G: 4.8621\n",
      "[1/25][748/782] Loss_D: 0.5165 Loss_G: 2.5616\n",
      "[1/25][749/782] Loss_D: 0.6894 Loss_G: 5.5548\n",
      "[1/25][750/782] Loss_D: 0.5810 Loss_G: 3.5443\n",
      "[1/25][751/782] Loss_D: 0.6400 Loss_G: 1.7325\n",
      "[1/25][752/782] Loss_D: 1.3409 Loss_G: 7.2789\n",
      "[1/25][753/782] Loss_D: 1.6099 Loss_G: 2.0686\n",
      "[1/25][754/782] Loss_D: 0.9680 Loss_G: 6.2051\n",
      "[1/25][755/782] Loss_D: 1.1801 Loss_G: 1.9963\n",
      "[1/25][756/782] Loss_D: 1.6095 Loss_G: 6.3116\n",
      "[1/25][757/782] Loss_D: 0.9813 Loss_G: 2.6506\n",
      "[1/25][758/782] Loss_D: 0.6521 Loss_G: 3.7442\n",
      "[1/25][759/782] Loss_D: 1.1707 Loss_G: 6.4496\n",
      "[1/25][760/782] Loss_D: 1.4381 Loss_G: 2.5842\n",
      "[1/25][761/782] Loss_D: 0.9519 Loss_G: 4.4683\n",
      "[1/25][762/782] Loss_D: 0.6035 Loss_G: 4.1311\n",
      "[1/25][763/782] Loss_D: 0.7736 Loss_G: 2.8145\n",
      "[1/25][764/782] Loss_D: 0.7828 Loss_G: 5.0270\n",
      "[1/25][765/782] Loss_D: 0.9461 Loss_G: 2.0848\n",
      "[1/25][766/782] Loss_D: 0.7417 Loss_G: 3.5888\n",
      "[1/25][767/782] Loss_D: 0.7646 Loss_G: 5.3526\n",
      "[1/25][768/782] Loss_D: 1.2143 Loss_G: 1.9749\n",
      "[1/25][769/782] Loss_D: 0.7875 Loss_G: 2.8793\n",
      "[1/25][770/782] Loss_D: 0.8735 Loss_G: 5.4116\n",
      "[1/25][771/782] Loss_D: 0.9327 Loss_G: 2.8951\n",
      "[1/25][772/782] Loss_D: 0.6615 Loss_G: 3.6089\n",
      "[1/25][773/782] Loss_D: 0.6218 Loss_G: 2.8471\n",
      "[1/25][774/782] Loss_D: 0.7599 Loss_G: 4.3867\n",
      "[1/25][775/782] Loss_D: 0.4540 Loss_G: 3.0917\n",
      "[1/25][776/782] Loss_D: 0.4605 Loss_G: 2.5910\n",
      "[1/25][777/782] Loss_D: 0.5477 Loss_G: 4.6824\n",
      "[1/25][778/782] Loss_D: 0.6549 Loss_G: 2.5420\n",
      "[1/25][779/782] Loss_D: 0.6023 Loss_G: 4.7194\n",
      "[1/25][780/782] Loss_D: 0.3660 Loss_G: 4.0707\n",
      "[1/25][781/782] Loss_D: 0.4649 Loss_G: 3.1690\n",
      "[2/25][0/782] Loss_D: 1.0717 Loss_G: 6.3266\n",
      "[2/25][1/782] Loss_D: 1.1556 Loss_G: 2.5424\n",
      "[2/25][2/782] Loss_D: 0.6880 Loss_G: 3.4560\n",
      "[2/25][3/782] Loss_D: 0.6659 Loss_G: 3.5835\n",
      "[2/25][4/782] Loss_D: 0.3382 Loss_G: 3.4803\n",
      "[2/25][5/782] Loss_D: 0.5193 Loss_G: 2.9658\n",
      "[2/25][6/782] Loss_D: 0.6429 Loss_G: 5.7163\n",
      "[2/25][7/782] Loss_D: 1.1147 Loss_G: 1.8556\n",
      "[2/25][8/782] Loss_D: 0.5682 Loss_G: 4.4785\n",
      "[2/25][9/782] Loss_D: 0.3194 Loss_G: 4.3208\n",
      "[2/25][10/782] Loss_D: 0.3063 Loss_G: 3.4380\n",
      "[2/25][11/782] Loss_D: 0.5986 Loss_G: 2.9255\n",
      "[2/25][12/782] Loss_D: 0.6311 Loss_G: 4.9769\n",
      "[2/25][13/782] Loss_D: 0.7044 Loss_G: 2.5913\n",
      "[2/25][14/782] Loss_D: 0.4961 Loss_G: 3.3020\n",
      "[2/25][15/782] Loss_D: 0.5473 Loss_G: 4.4452\n",
      "[2/25][16/782] Loss_D: 0.5778 Loss_G: 2.8798\n",
      "[2/25][17/782] Loss_D: 0.7806 Loss_G: 3.5164\n",
      "[2/25][18/782] Loss_D: 0.5208 Loss_G: 3.6991\n",
      "[2/25][19/782] Loss_D: 0.4957 Loss_G: 3.9653\n",
      "[2/25][20/782] Loss_D: 0.5799 Loss_G: 2.4572\n",
      "[2/25][21/782] Loss_D: 0.6651 Loss_G: 4.6187\n",
      "[2/25][22/782] Loss_D: 0.5591 Loss_G: 2.8777\n",
      "[2/25][23/782] Loss_D: 0.3358 Loss_G: 3.0606\n",
      "[2/25][24/782] Loss_D: 0.4846 Loss_G: 3.9555\n",
      "[2/25][25/782] Loss_D: 0.6444 Loss_G: 2.7385\n",
      "[2/25][26/782] Loss_D: 0.6001 Loss_G: 4.3708\n",
      "[2/25][27/782] Loss_D: 0.5725 Loss_G: 2.4798\n",
      "[2/25][28/782] Loss_D: 0.5340 Loss_G: 4.0177\n",
      "[2/25][29/782] Loss_D: 0.6867 Loss_G: 2.5455\n",
      "[2/25][30/782] Loss_D: 0.5720 Loss_G: 4.1904\n",
      "[2/25][31/782] Loss_D: 0.4953 Loss_G: 3.4493\n",
      "[2/25][32/782] Loss_D: 0.7998 Loss_G: 4.1219\n",
      "[2/25][33/782] Loss_D: 0.5809 Loss_G: 3.2507\n",
      "[2/25][34/782] Loss_D: 0.5325 Loss_G: 2.4412\n",
      "[2/25][35/782] Loss_D: 0.7216 Loss_G: 5.7922\n",
      "[2/25][36/782] Loss_D: 0.7025 Loss_G: 2.0832\n",
      "[2/25][37/782] Loss_D: 0.7149 Loss_G: 4.5566\n",
      "[2/25][38/782] Loss_D: 0.3406 Loss_G: 3.4294\n",
      "[2/25][39/782] Loss_D: 0.3024 Loss_G: 4.0613\n",
      "[2/25][40/782] Loss_D: 0.3761 Loss_G: 4.5309\n",
      "[2/25][41/782] Loss_D: 0.4270 Loss_G: 2.9152\n",
      "[2/25][42/782] Loss_D: 0.5333 Loss_G: 5.0268\n",
      "[2/25][43/782] Loss_D: 0.5724 Loss_G: 2.7277\n",
      "[2/25][44/782] Loss_D: 1.0053 Loss_G: 4.4654\n",
      "[2/25][45/782] Loss_D: 0.8006 Loss_G: 1.6517\n",
      "[2/25][46/782] Loss_D: 0.8473 Loss_G: 6.0440\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/25][47/782] Loss_D: 0.6617 Loss_G: 2.3845\n",
      "[2/25][48/782] Loss_D: 0.4814 Loss_G: 3.1543\n",
      "[2/25][49/782] Loss_D: 0.4423 Loss_G: 2.8674\n",
      "[2/25][50/782] Loss_D: 0.4940 Loss_G: 4.0793\n",
      "[2/25][51/782] Loss_D: 0.5086 Loss_G: 2.7906\n",
      "[2/25][52/782] Loss_D: 0.3963 Loss_G: 2.6660\n",
      "[2/25][53/782] Loss_D: 0.4046 Loss_G: 4.2817\n",
      "[2/25][54/782] Loss_D: 0.5528 Loss_G: 2.1228\n",
      "[2/25][55/782] Loss_D: 0.3987 Loss_G: 3.4442\n",
      "[2/25][56/782] Loss_D: 0.4833 Loss_G: 4.9435\n",
      "[2/25][57/782] Loss_D: 0.5171 Loss_G: 2.0322\n",
      "[2/25][58/782] Loss_D: 0.6158 Loss_G: 5.2600\n",
      "[2/25][59/782] Loss_D: 0.7343 Loss_G: 1.1274\n",
      "[2/25][60/782] Loss_D: 1.6110 Loss_G: 7.7522\n",
      "[2/25][61/782] Loss_D: 1.6828 Loss_G: 1.4264\n",
      "[2/25][62/782] Loss_D: 1.1409 Loss_G: 5.6492\n",
      "[2/25][63/782] Loss_D: 0.8049 Loss_G: 2.0953\n",
      "[2/25][64/782] Loss_D: 0.6605 Loss_G: 3.3802\n",
      "[2/25][65/782] Loss_D: 0.4625 Loss_G: 4.8685\n",
      "[2/25][66/782] Loss_D: 0.7170 Loss_G: 2.0406\n",
      "[2/25][67/782] Loss_D: 0.9258 Loss_G: 5.0484\n",
      "[2/25][68/782] Loss_D: 0.7001 Loss_G: 2.5831\n",
      "[2/25][69/782] Loss_D: 1.0236 Loss_G: 3.5492\n",
      "[2/25][70/782] Loss_D: 0.8373 Loss_G: 4.0892\n",
      "[2/25][71/782] Loss_D: 1.1472 Loss_G: 0.8406\n",
      "[2/25][72/782] Loss_D: 1.6537 Loss_G: 6.6021\n",
      "[2/25][73/782] Loss_D: 1.4512 Loss_G: 0.9052\n",
      "[2/25][74/782] Loss_D: 1.9134 Loss_G: 7.2326\n",
      "[2/25][75/782] Loss_D: 1.7605 Loss_G: 2.5789\n",
      "[2/25][76/782] Loss_D: 0.5509 Loss_G: 2.2221\n",
      "[2/25][77/782] Loss_D: 0.7419 Loss_G: 4.7340\n",
      "[2/25][78/782] Loss_D: 0.7220 Loss_G: 3.2245\n",
      "[2/25][79/782] Loss_D: 0.3696 Loss_G: 3.0515\n",
      "[2/25][80/782] Loss_D: 0.3423 Loss_G: 3.6414\n",
      "[2/25][81/782] Loss_D: 0.4049 Loss_G: 3.0906\n",
      "[2/25][82/782] Loss_D: 0.5502 Loss_G: 3.2048\n",
      "[2/25][83/782] Loss_D: 0.6358 Loss_G: 2.5447\n",
      "[2/25][84/782] Loss_D: 0.9971 Loss_G: 3.3904\n",
      "[2/25][85/782] Loss_D: 1.0305 Loss_G: 1.7157\n",
      "[2/25][86/782] Loss_D: 1.2422 Loss_G: 5.4872\n",
      "[2/25][87/782] Loss_D: 1.1061 Loss_G: 2.9416\n",
      "[2/25][88/782] Loss_D: 0.7279 Loss_G: 1.8030\n",
      "[2/25][89/782] Loss_D: 0.8139 Loss_G: 4.9574\n",
      "[2/25][90/782] Loss_D: 0.8492 Loss_G: 3.0914\n",
      "[2/25][91/782] Loss_D: 0.4642 Loss_G: 2.9090\n",
      "[2/25][92/782] Loss_D: 0.6295 Loss_G: 3.9859\n",
      "[2/25][93/782] Loss_D: 0.3391 Loss_G: 4.5456\n",
      "[2/25][94/782] Loss_D: 0.8498 Loss_G: 1.4162\n",
      "[2/25][95/782] Loss_D: 0.7509 Loss_G: 5.1809\n",
      "[2/25][96/782] Loss_D: 0.6189 Loss_G: 3.1423\n",
      "[2/25][97/782] Loss_D: 0.5955 Loss_G: 4.9535\n",
      "[2/25][98/782] Loss_D: 0.5186 Loss_G: 3.1143\n",
      "[2/25][99/782] Loss_D: 0.5720 Loss_G: 1.8795\n",
      "[2/25][100/782] Loss_D: 1.2593 Loss_G: 7.0621\n",
      "[2/25][101/782] Loss_D: 1.2466 Loss_G: 2.8442\n",
      "[2/25][102/782] Loss_D: 0.5882 Loss_G: 3.1302\n",
      "[2/25][103/782] Loss_D: 0.8644 Loss_G: 2.6561\n",
      "[2/25][104/782] Loss_D: 0.6434 Loss_G: 4.4645\n",
      "[2/25][105/782] Loss_D: 0.6981 Loss_G: 2.4127\n",
      "[2/25][106/782] Loss_D: 0.6027 Loss_G: 3.7267\n",
      "[2/25][107/782] Loss_D: 0.5060 Loss_G: 4.0298\n",
      "[2/25][108/782] Loss_D: 0.6406 Loss_G: 2.1963\n",
      "[2/25][109/782] Loss_D: 0.9236 Loss_G: 4.4555\n",
      "[2/25][110/782] Loss_D: 0.6123 Loss_G: 2.0411\n",
      "[2/25][111/782] Loss_D: 0.5992 Loss_G: 5.7241\n",
      "[2/25][112/782] Loss_D: 0.2277 Loss_G: 4.9050\n",
      "[2/25][113/782] Loss_D: 0.4795 Loss_G: 2.2583\n",
      "[2/25][114/782] Loss_D: 0.5036 Loss_G: 3.9326\n",
      "[2/25][115/782] Loss_D: 0.3088 Loss_G: 4.0774\n",
      "[2/25][116/782] Loss_D: 0.6907 Loss_G: 2.4683\n",
      "[2/25][117/782] Loss_D: 0.6245 Loss_G: 4.6715\n",
      "[2/25][118/782] Loss_D: 0.8276 Loss_G: 2.2439\n",
      "[2/25][119/782] Loss_D: 0.4164 Loss_G: 3.6346\n",
      "[2/25][120/782] Loss_D: 0.5547 Loss_G: 4.4083\n",
      "[2/25][121/782] Loss_D: 0.6393 Loss_G: 2.5041\n",
      "[2/25][122/782] Loss_D: 0.5631 Loss_G: 3.7831\n",
      "[2/25][123/782] Loss_D: 0.6887 Loss_G: 3.2039\n",
      "[2/25][124/782] Loss_D: 0.7099 Loss_G: 4.5839\n",
      "[2/25][125/782] Loss_D: 1.1620 Loss_G: 1.1004\n",
      "[2/25][126/782] Loss_D: 1.1275 Loss_G: 5.3344\n",
      "[2/25][127/782] Loss_D: 0.5784 Loss_G: 2.7538\n",
      "[2/25][128/782] Loss_D: 0.6638 Loss_G: 4.7397\n",
      "[2/25][129/782] Loss_D: 0.6249 Loss_G: 2.5037\n",
      "[2/25][130/782] Loss_D: 0.5890 Loss_G: 3.1805\n",
      "[2/25][131/782] Loss_D: 0.7381 Loss_G: 3.2325\n",
      "[2/25][132/782] Loss_D: 0.4855 Loss_G: 3.3389\n",
      "[2/25][133/782] Loss_D: 0.4629 Loss_G: 3.8744\n",
      "[2/25][134/782] Loss_D: 0.5232 Loss_G: 2.6120\n",
      "[2/25][135/782] Loss_D: 1.1646 Loss_G: 6.2600\n",
      "[2/25][136/782] Loss_D: 0.9885 Loss_G: 2.2684\n",
      "[2/25][137/782] Loss_D: 0.6392 Loss_G: 4.9310\n",
      "[2/25][138/782] Loss_D: 0.3362 Loss_G: 3.9131\n",
      "[2/25][139/782] Loss_D: 0.3646 Loss_G: 3.4032\n",
      "[2/25][140/782] Loss_D: 0.2275 Loss_G: 3.7371\n",
      "[2/25][141/782] Loss_D: 0.3045 Loss_G: 3.6680\n",
      "[2/25][142/782] Loss_D: 0.3115 Loss_G: 4.8605\n",
      "[2/25][143/782] Loss_D: 0.5229 Loss_G: 3.4286\n",
      "[2/25][144/782] Loss_D: 0.4389 Loss_G: 3.3408\n",
      "[2/25][145/782] Loss_D: 0.4826 Loss_G: 5.0488\n",
      "[2/25][146/782] Loss_D: 0.6255 Loss_G: 3.1808\n",
      "[2/25][147/782] Loss_D: 0.4225 Loss_G: 3.9439\n",
      "[2/25][148/782] Loss_D: 0.2892 Loss_G: 4.3543\n",
      "[2/25][149/782] Loss_D: 0.2908 Loss_G: 3.7236\n",
      "[2/25][150/782] Loss_D: 0.1772 Loss_G: 3.7735\n",
      "[2/25][151/782] Loss_D: 0.4932 Loss_G: 3.6995\n",
      "[2/25][152/782] Loss_D: 0.6047 Loss_G: 3.9053\n",
      "[2/25][153/782] Loss_D: 0.3407 Loss_G: 3.8949\n",
      "[2/25][154/782] Loss_D: 0.7157 Loss_G: 2.8353\n",
      "[2/25][155/782] Loss_D: 0.5442 Loss_G: 4.8627\n",
      "[2/25][156/782] Loss_D: 0.8978 Loss_G: 2.0295\n",
      "[2/25][157/782] Loss_D: 0.8545 Loss_G: 4.9662\n",
      "[2/25][158/782] Loss_D: 0.4577 Loss_G: 3.6150\n",
      "[2/25][159/782] Loss_D: 0.3076 Loss_G: 3.6529\n",
      "[2/25][160/782] Loss_D: 0.4850 Loss_G: 4.4469\n",
      "[2/25][161/782] Loss_D: 0.7441 Loss_G: 1.6466\n",
      "[2/25][162/782] Loss_D: 0.7391 Loss_G: 4.9621\n",
      "[2/25][163/782] Loss_D: 0.7495 Loss_G: 1.9790\n",
      "[2/25][164/782] Loss_D: 0.5872 Loss_G: 4.6091\n",
      "[2/25][165/782] Loss_D: 0.5719 Loss_G: 3.0604\n",
      "[2/25][166/782] Loss_D: 0.6172 Loss_G: 3.6305\n",
      "[2/25][167/782] Loss_D: 0.8659 Loss_G: 1.5254\n",
      "[2/25][168/782] Loss_D: 0.7873 Loss_G: 3.4600\n",
      "[2/25][169/782] Loss_D: 0.5310 Loss_G: 2.8217\n",
      "[2/25][170/782] Loss_D: 0.4759 Loss_G: 4.1674\n",
      "[2/25][171/782] Loss_D: 0.4364 Loss_G: 2.7064\n",
      "[2/25][172/782] Loss_D: 0.5144 Loss_G: 3.6777\n",
      "[2/25][173/782] Loss_D: 0.4904 Loss_G: 3.4933\n",
      "[2/25][174/782] Loss_D: 0.5282 Loss_G: 1.9532\n",
      "[2/25][175/782] Loss_D: 0.7112 Loss_G: 4.8516\n",
      "[2/25][176/782] Loss_D: 0.4956 Loss_G: 2.9031\n",
      "[2/25][177/782] Loss_D: 0.6075 Loss_G: 3.8358\n",
      "[2/25][178/782] Loss_D: 0.4871 Loss_G: 2.8211\n",
      "[2/25][179/782] Loss_D: 0.4167 Loss_G: 3.0607\n",
      "[2/25][180/782] Loss_D: 0.5150 Loss_G: 3.1485\n",
      "[2/25][181/782] Loss_D: 0.5035 Loss_G: 4.1486\n",
      "[2/25][182/782] Loss_D: 0.6041 Loss_G: 2.4185\n",
      "[2/25][183/782] Loss_D: 0.6791 Loss_G: 3.8552\n",
      "[2/25][184/782] Loss_D: 0.6532 Loss_G: 2.0404\n",
      "[2/25][185/782] Loss_D: 0.5779 Loss_G: 5.7782\n",
      "[2/25][186/782] Loss_D: 0.9487 Loss_G: 1.8838\n",
      "[2/25][187/782] Loss_D: 0.7450 Loss_G: 4.6604\n",
      "[2/25][188/782] Loss_D: 0.2138 Loss_G: 4.1947\n",
      "[2/25][189/782] Loss_D: 0.3288 Loss_G: 3.5318\n",
      "[2/25][190/782] Loss_D: 0.5729 Loss_G: 3.2872\n",
      "[2/25][191/782] Loss_D: 0.5882 Loss_G: 2.8864\n",
      "[2/25][192/782] Loss_D: 0.3545 Loss_G: 3.5560\n",
      "[2/25][193/782] Loss_D: 0.5736 Loss_G: 2.6331\n",
      "[2/25][194/782] Loss_D: 0.4624 Loss_G: 4.2938\n",
      "[2/25][195/782] Loss_D: 0.4185 Loss_G: 3.4406\n",
      "[2/25][196/782] Loss_D: 0.3216 Loss_G: 3.5621\n",
      "[2/25][197/782] Loss_D: 0.3930 Loss_G: 3.5452\n",
      "[2/25][198/782] Loss_D: 0.5634 Loss_G: 2.8637\n",
      "[2/25][199/782] Loss_D: 0.7002 Loss_G: 4.7242\n",
      "[2/25][200/782] Loss_D: 0.5569 Loss_G: 1.7715\n",
      "[2/25][201/782] Loss_D: 0.9505 Loss_G: 7.9746\n",
      "[2/25][202/782] Loss_D: 2.5428 Loss_G: 1.0661\n",
      "[2/25][203/782] Loss_D: 1.4285 Loss_G: 6.6579\n",
      "[2/25][204/782] Loss_D: 0.9459 Loss_G: 2.7813\n",
      "[2/25][205/782] Loss_D: 0.7387 Loss_G: 3.9439\n",
      "[2/25][206/782] Loss_D: 0.7199 Loss_G: 2.0526\n",
      "[2/25][207/782] Loss_D: 0.9647 Loss_G: 5.3847\n",
      "[2/25][208/782] Loss_D: 0.9122 Loss_G: 2.4097\n",
      "[2/25][209/782] Loss_D: 0.9148 Loss_G: 2.7178\n",
      "[2/25][210/782] Loss_D: 0.6516 Loss_G: 4.5857\n",
      "[2/25][211/782] Loss_D: 0.6366 Loss_G: 2.6715\n",
      "[2/25][212/782] Loss_D: 0.7722 Loss_G: 4.3355\n",
      "[2/25][213/782] Loss_D: 0.4876 Loss_G: 2.7362\n",
      "[2/25][214/782] Loss_D: 0.5181 Loss_G: 2.2434\n",
      "[2/25][215/782] Loss_D: 0.8145 Loss_G: 4.0790\n",
      "[2/25][216/782] Loss_D: 0.5391 Loss_G: 2.7581\n",
      "[2/25][217/782] Loss_D: 0.5014 Loss_G: 3.1456\n",
      "[2/25][218/782] Loss_D: 0.4193 Loss_G: 3.1675\n",
      "[2/25][219/782] Loss_D: 0.5980 Loss_G: 2.5508\n",
      "[2/25][220/782] Loss_D: 0.5809 Loss_G: 3.9772\n",
      "[2/25][221/782] Loss_D: 0.9303 Loss_G: 1.6237\n",
      "[2/25][222/782] Loss_D: 1.2651 Loss_G: 6.0918\n",
      "[2/25][223/782] Loss_D: 1.9007 Loss_G: 1.0077\n",
      "[2/25][224/782] Loss_D: 1.7056 Loss_G: 4.9247\n",
      "[2/25][225/782] Loss_D: 1.1301 Loss_G: 0.6436\n",
      "[2/25][226/782] Loss_D: 2.0454 Loss_G: 5.9717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/25][227/782] Loss_D: 2.1745 Loss_G: 1.9912\n",
      "[2/25][228/782] Loss_D: 0.7058 Loss_G: 1.4572\n",
      "[2/25][229/782] Loss_D: 0.9690 Loss_G: 5.8747\n",
      "[2/25][230/782] Loss_D: 1.1655 Loss_G: 1.6145\n",
      "[2/25][231/782] Loss_D: 0.9261 Loss_G: 3.1554\n",
      "[2/25][232/782] Loss_D: 0.9253 Loss_G: 2.7417\n",
      "[2/25][233/782] Loss_D: 1.1893 Loss_G: 1.5713\n",
      "[2/25][234/782] Loss_D: 1.3351 Loss_G: 4.6588\n",
      "[2/25][235/782] Loss_D: 1.2107 Loss_G: 1.8153\n",
      "[2/25][236/782] Loss_D: 0.5195 Loss_G: 3.3767\n",
      "[2/25][237/782] Loss_D: 0.5392 Loss_G: 3.1854\n",
      "[2/25][238/782] Loss_D: 0.8677 Loss_G: 1.6368\n",
      "[2/25][239/782] Loss_D: 0.8374 Loss_G: 3.5446\n",
      "[2/25][240/782] Loss_D: 0.5525 Loss_G: 2.6668\n",
      "[2/25][241/782] Loss_D: 0.4436 Loss_G: 2.5849\n",
      "[2/25][242/782] Loss_D: 0.6340 Loss_G: 4.2506\n",
      "[2/25][243/782] Loss_D: 0.7567 Loss_G: 1.9482\n",
      "[2/25][244/782] Loss_D: 0.7249 Loss_G: 2.9524\n",
      "[2/25][245/782] Loss_D: 0.4420 Loss_G: 3.3357\n",
      "[2/25][246/782] Loss_D: 0.8015 Loss_G: 2.5074\n",
      "[2/25][247/782] Loss_D: 0.5456 Loss_G: 3.2680\n",
      "[2/25][248/782] Loss_D: 0.8491 Loss_G: 2.1065\n",
      "[2/25][249/782] Loss_D: 0.9198 Loss_G: 5.0074\n",
      "[2/25][250/782] Loss_D: 0.9099 Loss_G: 1.9639\n",
      "[2/25][251/782] Loss_D: 0.6326 Loss_G: 2.8795\n",
      "[2/25][252/782] Loss_D: 0.6778 Loss_G: 4.3647\n",
      "[2/25][253/782] Loss_D: 0.5039 Loss_G: 3.1819\n",
      "[2/25][254/782] Loss_D: 0.6024 Loss_G: 2.9253\n",
      "[2/25][255/782] Loss_D: 0.5426 Loss_G: 3.5788\n",
      "[2/25][256/782] Loss_D: 0.7725 Loss_G: 3.0585\n",
      "[2/25][257/782] Loss_D: 0.5568 Loss_G: 2.7838\n",
      "[2/25][258/782] Loss_D: 0.4532 Loss_G: 3.8881\n",
      "[2/25][259/782] Loss_D: 0.4242 Loss_G: 3.1646\n",
      "[2/25][260/782] Loss_D: 0.4844 Loss_G: 3.9069\n",
      "[2/25][261/782] Loss_D: 0.3855 Loss_G: 2.7512\n",
      "[2/25][262/782] Loss_D: 0.6320 Loss_G: 5.3151\n",
      "[2/25][263/782] Loss_D: 0.9701 Loss_G: 1.7573\n",
      "[2/25][264/782] Loss_D: 0.4945 Loss_G: 4.3130\n",
      "[2/25][265/782] Loss_D: 0.4433 Loss_G: 3.2229\n",
      "[2/25][266/782] Loss_D: 0.5641 Loss_G: 3.4020\n",
      "[2/25][267/782] Loss_D: 0.9160 Loss_G: 3.6217\n",
      "[2/25][268/782] Loss_D: 0.8756 Loss_G: 1.3547\n",
      "[2/25][269/782] Loss_D: 1.1946 Loss_G: 6.3268\n",
      "[2/25][270/782] Loss_D: 1.2520 Loss_G: 1.1389\n",
      "[2/25][271/782] Loss_D: 1.6719 Loss_G: 6.7609\n",
      "[2/25][272/782] Loss_D: 1.6419 Loss_G: 1.4805\n",
      "[2/25][273/782] Loss_D: 1.3781 Loss_G: 4.8804\n",
      "[2/25][274/782] Loss_D: 0.7363 Loss_G: 3.3336\n",
      "[2/25][275/782] Loss_D: 0.8650 Loss_G: 2.3735\n",
      "[2/25][276/782] Loss_D: 0.9089 Loss_G: 3.7025\n",
      "[2/25][277/782] Loss_D: 0.7163 Loss_G: 3.2465\n",
      "[2/25][278/782] Loss_D: 0.7074 Loss_G: 3.7499\n",
      "[2/25][279/782] Loss_D: 0.8595 Loss_G: 2.8095\n",
      "[2/25][280/782] Loss_D: 1.4133 Loss_G: 3.5658\n",
      "[2/25][281/782] Loss_D: 0.6066 Loss_G: 3.0160\n",
      "[2/25][282/782] Loss_D: 0.7334 Loss_G: 3.7756\n",
      "[2/25][283/782] Loss_D: 0.5203 Loss_G: 2.9813\n",
      "[2/25][284/782] Loss_D: 1.0680 Loss_G: 5.2727\n",
      "[2/25][285/782] Loss_D: 1.8658 Loss_G: 0.8404\n",
      "[2/25][286/782] Loss_D: 1.3699 Loss_G: 5.4177\n",
      "[2/25][287/782] Loss_D: 1.2703 Loss_G: 1.7982\n",
      "[2/25][288/782] Loss_D: 0.9457 Loss_G: 4.2557\n",
      "[2/25][289/782] Loss_D: 0.5098 Loss_G: 3.4862\n",
      "[2/25][290/782] Loss_D: 0.8861 Loss_G: 4.1727\n",
      "[2/25][291/782] Loss_D: 0.8178 Loss_G: 2.2876\n",
      "[2/25][292/782] Loss_D: 1.0866 Loss_G: 4.5662\n",
      "[2/25][293/782] Loss_D: 0.8074 Loss_G: 2.8910\n",
      "[2/25][294/782] Loss_D: 0.6721 Loss_G: 3.6711\n",
      "[2/25][295/782] Loss_D: 0.6900 Loss_G: 3.7032\n",
      "[2/25][296/782] Loss_D: 0.4742 Loss_G: 4.0086\n",
      "[2/25][297/782] Loss_D: 0.4012 Loss_G: 3.6078\n",
      "[2/25][298/782] Loss_D: 0.4360 Loss_G: 3.0130\n",
      "[2/25][299/782] Loss_D: 0.4391 Loss_G: 3.7885\n",
      "[2/25][300/782] Loss_D: 0.9005 Loss_G: 4.7017\n",
      "[2/25][301/782] Loss_D: 0.5688 Loss_G: 2.5529\n",
      "[2/25][302/782] Loss_D: 1.0147 Loss_G: 5.4006\n",
      "[2/25][303/782] Loss_D: 1.0470 Loss_G: 1.5581\n",
      "[2/25][304/782] Loss_D: 1.3829 Loss_G: 6.0566\n",
      "[2/25][305/782] Loss_D: 1.4157 Loss_G: 1.1462\n",
      "[2/25][306/782] Loss_D: 0.9533 Loss_G: 4.6688\n",
      "[2/25][307/782] Loss_D: 0.4672 Loss_G: 3.4852\n",
      "[2/25][308/782] Loss_D: 0.3903 Loss_G: 3.1022\n",
      "[2/25][309/782] Loss_D: 0.4456 Loss_G: 3.3825\n",
      "[2/25][310/782] Loss_D: 0.5543 Loss_G: 2.8729\n",
      "[2/25][311/782] Loss_D: 0.4563 Loss_G: 4.2897\n",
      "[2/25][312/782] Loss_D: 0.3177 Loss_G: 3.7890\n",
      "[2/25][313/782] Loss_D: 0.7645 Loss_G: 1.9221\n",
      "[2/25][314/782] Loss_D: 0.8784 Loss_G: 3.9519\n",
      "[2/25][315/782] Loss_D: 0.7593 Loss_G: 1.7854\n",
      "[2/25][316/782] Loss_D: 0.9022 Loss_G: 3.2663\n",
      "[2/25][317/782] Loss_D: 1.1553 Loss_G: 2.1271\n",
      "[2/25][318/782] Loss_D: 0.4986 Loss_G: 3.0044\n",
      "[2/25][319/782] Loss_D: 0.6425 Loss_G: 3.0485\n",
      "[2/25][320/782] Loss_D: 0.4031 Loss_G: 3.8592\n",
      "[2/25][321/782] Loss_D: 0.3820 Loss_G: 2.8811\n",
      "[2/25][322/782] Loss_D: 0.2652 Loss_G: 3.2916\n",
      "[2/25][323/782] Loss_D: 0.5995 Loss_G: 2.6773\n",
      "[2/25][324/782] Loss_D: 0.5555 Loss_G: 3.4629\n",
      "[2/25][325/782] Loss_D: 0.4641 Loss_G: 3.2599\n",
      "[2/25][326/782] Loss_D: 0.5120 Loss_G: 2.8438\n",
      "[2/25][327/782] Loss_D: 0.4952 Loss_G: 3.5818\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(25):\n",
    "    for i, data in enumerate(dataloader,0):\n",
    "        netD.zero_grad()    #Updating the weights of the Discriminator\n",
    "        real, _ = data      #Training the Discriminator with the real images\n",
    "        input = Variable(real)\n",
    "        target = Variable(torch.ones(input.size()[0]))\n",
    "        output = netD(input)\n",
    "        errD_real = criterion(output,target)\n",
    "        \n",
    "        noise = Variable(torch.randn(input.size()[0],100,1,1))  #Training the Discriminator with the fake images\n",
    "        fake = netG(noise)\n",
    "        target = Variable(torch.zeros(input.size()[0]))\n",
    "        output = netD(fake.detach())\n",
    "        errD_fake = criterion(output,target)\n",
    "        \n",
    "        errD = errD_real + errD_fake\n",
    "        \n",
    "        errD.backward()\n",
    "        optimizerD.step()\n",
    "        \n",
    "        netG.zero_grad()  #Updating weights of the neural network\n",
    "        target = Variable(torch.ones(input.size()[0]))\n",
    "        output = netD(fake)\n",
    "        errG = criterion(output,target)\n",
    "        errG.backward()\n",
    "        optimizerG.step()\n",
    "        \n",
    "        print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f' % (epoch, 25, i, len(dataloader), errD.item(), errG.item()))\n",
    "        if i % 100 == 0:\n",
    "            vutils.save_image(real, '%s/real_samples.png' % \"/Users/vishalsingh/Desktop/Data/ML/ComputerVision/KirilEremenko/Computer_Vision_A_Z_Template_Folder/Module 3 - GANs/Module 3 - GANs\", normalize = True)\n",
    "            fake = netG(noise)\n",
    "            vutils.save_image(fake.data, '%s/fake_samples_epoch_%03d.png' % (\"/Users/vishalsingh/Desktop/Data/ML/ComputerVision/KirilEremenko/Computer_Vision_A_Z_Template_Folder/Module 3 - GANs/Module 3 - GANs\", epoch), normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
